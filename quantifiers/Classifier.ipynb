{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier  approach\n",
    "---\n",
    "This approach assumes that quantifiers are learned as a group and that essentially each q quantifier example is a negative example for all other quantifiers q'.\n",
    "\n",
    "The classifier is in effect a solver for which q makes the sentence \"Q as are bs\" most likely given an input scene s.\n",
    "\n",
    "This enables us to use not only the quantifier quantify evaluation methods but the classifier in order to generate a teacher-student scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### my class imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Q.quants import *\n",
    "from Q.models import Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras and TF imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, LSTM, Embedding, Dense, Conv1D, Input, Bidirectional, RepeatVector, Dropout, LeakyReLU, Flatten\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras backend:  tensorflow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[LogicalDevice(name='/device:CPU:0', device_type='CPU'),\n",
       " LogicalDevice(name='/device:XLA_CPU:0', device_type='XLA_CPU')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.3)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "print(\"Keras backend: \", tf.python.keras.backend.backend())\n",
    "tf.python.keras.backend.set_session(sess)\n",
    "tf.config.list_logical_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import partial, update_wrapper\n",
    "\n",
    "# def wrapped_partial(func, *args, **kwargs):\n",
    "#     |   partial_func = partial(func, *args, **kwargs)\n",
    "#         update_wrapper(partial_func, func)\n",
    "#         return partial_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep dense classifier model builder method\n",
    "def DDNN(quantifiers):\n",
    "    model= Sequential()\n",
    "    model.add(Dense(scene_len, activation=\"relu\", name=\"input\"))\n",
    "    model.add(Dropout(0.25, name=\"dropout_1\"))\n",
    "    model.add(Dense(100, activation=\"relu\", name=\"dense_2\"))\n",
    "    model.add(Dropout(0.25, name=\"dropout_2\"))\n",
    "    model.add(Dense(50, activation=\"relu\", name=\"dense_3\"))\n",
    "    model.add(Dropout(0.25, name=\"dropout_3\"))\n",
    "    model.add(Dense(len(quantifiers), activation='softmax', name=\"softmax_1\"))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Precision(),\n",
    "                                                                              tf.keras.metrics.Recall()])\n",
    "    return model, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense classifier model builder method\n",
    "def DNN(quantifiers):\n",
    "    model= Sequential()\n",
    "    model.add(Dense(scene_len, activation=\"relu\", name=\"input\"))\n",
    "    model.add(Dropout(0.5, name=\"dropout_1\"))\n",
    "    model.add(Dense(len(quantifiers), activation='softmax', name=\"softmax_1\"))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Precision(),\n",
    "                                                                              tf.keras.metrics.Recall()])\n",
    "    return model, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import initializers\n",
    "\n",
    "# Convolutional classifier model builder method\n",
    "class CNN(Classifier):\n",
    "    \n",
    "    def build():\n",
    "        model=Sequential()\n",
    "        model.add(Conv1D(filters=2, kernel_size=1, \n",
    "                     use_bias=False, \n",
    "                     input_shape=(scene_len, len(symbols)), name=\"conv_1\"))\n",
    "        model.add(Dropout(0.5, name=\"dropout_1\"))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(len(quantifiers),\n",
    "#                         kernel_initializer=\"constant\", trainable=False, use_bias=False,\n",
    "                        activation='softmax', name=\"softmax_1\"))\n",
    "        # Compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Precision(),\n",
    "                                                                                  tf.keras.metrics.Recall()])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import initializers\n",
    "\n",
    "# Convolutional classifier model builder method\n",
    "def CNNBuilder(quantifiers):\n",
    "    model= Sequential()\n",
    "    model.add(Conv1D(filters=2, kernel_size=1, \n",
    "                     use_bias=False, \n",
    "                     input_shape=(scene_len, len(symbols)), name=\"conv_1\"))\n",
    "    model.add(Dropout(0.5, name=\"dropout_1\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(len(quantifiers),\n",
    "#                     kernel_initializer=\"constant\", trainable=False, use_bias=False, \n",
    "                    activation='softmax', name=\"softmax_1\"))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Precision(),\n",
    "                                                                              tf.keras.metrics.Recall()])\n",
    "    return model, True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifier sets for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_quantifiers = [The(), Both(), No(), All(), Some(), Most()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnatural_quantifiers = [MinMax(2, 10), MinMax(3, 6), Or([MinMax(2, 5), MinMax(10, 20)])]\n",
    "# unnatural_quantifiers = [MinMax(2, 5), MinMax(8, 10), MinMax(12, 15), MinMax(17, 20), MinMax(24, 30), MinMax(37, 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teach(classifier, min_len=0, max_len=scene_len, repeat=1, epochs=50, batch_size=10):\n",
    "    \"\"\"\n",
    "    This method teaches a classifier to classify its quantifiers\n",
    "    \n",
    "    repeat: teacher student learning for repeat # of rounds\n",
    "    epochs, batch_size: parameters passed to tensorflow learning\n",
    "    min_len, max_len: genereated scene length limits for training (to test generalization)\n",
    "    \"\"\"\n",
    "    last_classifier = None\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "#     with tf.device(\"/gpu:0\"):\n",
    "        # iterate while using the previous model as label generator\n",
    "        for _ in range(repeat):\n",
    "            # generate fit and test model\n",
    "            if last_classifier:\n",
    "                train_scenes_labels = classifier.generate_labeled_scenes(last_classifier, min_len, max_len)\n",
    "                test_scenes_labels = classifier.generate_labeled_scenes(last_classifier)\n",
    "            else:\n",
    "                train_scenes_labels = classifier.generate_labeled_scenes(min_len, max_len)\n",
    "                test_scenes_labels = classifier.generate_labeled_scenes()\n",
    "            classifier.fit(*train_scenes_labels, epochs=epochs, batch_size=batch_size)\n",
    "            classifier.test(*test_scenes_labels)\n",
    "            classifier.test_random(1000)\n",
    "            last_classifier = classifier.clone()\n",
    "        return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_classifier = teach(Classifier(natural_quantifiers, CNN), epochs=50, max_len=100)\n",
    "# natural_classifier = teach(Classifier(natural_quantifiers, DNN), epochs=500, repeat=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# unnatural_model = teach(Classifier(unnatural_quantifiers, CNN), epochs=50, max_len=100)\n",
    "unnatural_model = teach(Classifier(unnatural_quantifiers, DNN), epochs=50, max_len=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
