{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier  approach\n",
    "---\n",
    "This approach assumes that quantifiers are learned as a group and that essentially each q quantifier example is a negative example for all other quantifiers q'.\n",
    "\n",
    "The classifier is in effect a solver for which q makes the sentence \"Q as are bs\" most likely given an input scene s.\n",
    "\n",
    "This enables us to use not only the quantifier quantify evaluation methods but the classifier in order to generate a teacher-student scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### my class imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from quants.quantifiers import *\n",
    "from quants.models import Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras and TF imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, LSTM, Embedding, Dense, Conv1D, Input, Bidirectional, RepeatVector, Dropout, LeakyReLU, Flatten\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras backend:  tensorflow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[LogicalDevice(name='/device:CPU:0', device_type='CPU'),\n",
       " LogicalDevice(name='/device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " LogicalDevice(name='/device:XLA_GPU:0', device_type='XLA_GPU'),\n",
       " LogicalDevice(name='/device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.3)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "print(\"Keras backend: \", tf.python.keras.backend.backend())\n",
    "tf.python.keras.backend.set_session(sess)\n",
    "tf.config.list_logical_devices()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDNNClassifier(Classifier):\n",
    "    \"\"\" deep dense classifier model builder method \"\"\"\n",
    "    \n",
    "    def build(self):\n",
    "        model= Sequential()\n",
    "        model.add(Dense(Quantifier.scene_len, activation=\"relu\", name=\"input\"))\n",
    "        model.add(Dropout(0.25, name=\"dropout_1\"))\n",
    "        model.add(Dense(100, activation=\"relu\", name=\"dense_2\"))\n",
    "        model.add(Dropout(0.25, name=\"dropout_2\"))\n",
    "        model.add(Dense(50, activation=\"relu\", name=\"dense_3\"))\n",
    "        model.add(Dropout(0.25, name=\"dropout_3\"))\n",
    "        model.add(Dense(len(self._quantifiers), activation='softmax', name=\"softmax_1\"))\n",
    "        # Compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Precision(),\n",
    "                                                                                  tf.keras.metrics.Recall()])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNClassifier(Classifier):\n",
    "    \"\"\" dense classifier model builder method \"\"\"\n",
    "    \n",
    "    def build(self):\n",
    "        model= Sequential()\n",
    "        model.add(Dense(Quantifier.scene_len, activation=\"relu\", name=\"input\"))\n",
    "        model.add(Dropout(0.5, name=\"dropout_1\"))\n",
    "        model.add(Dense(len(self._quantifiers), activation='softmax', name=\"softmax_1\"))\n",
    "        # Compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Precision(),\n",
    "                                                                                  tf.keras.metrics.Recall()])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import initializers\n",
    "from keras.utils import np_utils\n",
    "\n",
    "class CNNClassifier(Classifier):\n",
    "    \"\"\" Convolutional classifier model builder method \"\"\"\n",
    "\n",
    "    def build(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=4, kernel_size=1,\n",
    "                         kernel_initializer=\"constant\",\n",
    "                         use_bias=False,\n",
    "                         input_shape=(Quantifier.scene_len, len(symbols)), name=\"conv_1\"))\n",
    "        model.add(Dropout(0.5, name=\"dropout_1\"))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(len(self._quantifiers),\n",
    "                        # kernel_initializer=\"constant\", trainable=False, \n",
    "                        use_bias=False,\n",
    "                        activation='softmax', name=\"softmax_1\"))\n",
    "        # Compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Precision(),\n",
    "                                                                                  tf.keras.metrics.Recall()])\n",
    "        return model\n",
    "\n",
    "    def prepare(self, scenes):\n",
    "        return np_utils.to_categorical(scenes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifier sets for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_quantifiers = [The(), Both(), No(), All(), Some(), Most()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unnatural_quantifiers = [MinMax(2, 10), MinMax(3, 6), Or([MinMax(2, 5), MinMax(10, 20)])]\n",
    "unnatural_quantifiers = [MinMax(2, 5), MinMax(8, 10), MinMax(12, 15), MinMax(17, 20), MinMax(24, 30), MinMax(37, 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNClassifier model classifies ['All()' 'Both()' 'Most()' 'No()' 'Some()' 'The()']\n",
      "Epoch 1/500\n",
      "6000/6000 [==============================] - 1s 156us/step - loss: 0.9715 - precision_14: 0.6986 - recall_14: 0.1747\n",
      "Epoch 2/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.7232 - precision_14: 0.7540 - recall_14: 0.3458\n",
      "Epoch 3/500\n",
      "6000/6000 [==============================] - 1s 150us/step - loss: 0.6641 - precision_14: 0.7471 - recall_14: 0.4233\n",
      "Epoch 4/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.6252 - precision_14: 0.7456 - recall_14: 0.4725\n",
      "Epoch 5/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.6049 - precision_14: 0.7480 - recall_14: 0.5057\n",
      "Epoch 6/500\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.5905 - precision_14: 0.7498 - recall_14: 0.5311\n",
      "Epoch 7/500\n",
      "6000/6000 [==============================] - 1s 168us/step - loss: 0.5835 - precision_14: 0.7508 - recall_14: 0.5507\n",
      "Epoch 8/500\n",
      "6000/6000 [==============================] - 1s 190us/step - loss: 0.5857 - precision_14: 0.7516 - recall_14: 0.5671\n",
      "Epoch 9/500\n",
      "6000/6000 [==============================] - 1s 185us/step - loss: 0.5786 - precision_14: 0.7515 - recall_14: 0.5791\n",
      "Epoch 10/500\n",
      "6000/6000 [==============================] - 1s 182us/step - loss: 0.5671 - precision_14: 0.7525 - recall_14: 0.5898\n",
      "Epoch 11/500\n",
      "6000/6000 [==============================] - 1s 182us/step - loss: 0.5546 - precision_14: 0.7541 - recall_14: 0.5995\n",
      "Epoch 12/500\n",
      "6000/6000 [==============================] - 1s 167us/step - loss: 0.5586 - precision_14: 0.7548 - recall_14: 0.6078\n",
      "Epoch 13/500\n",
      "6000/6000 [==============================] - 1s 160us/step - loss: 0.5560 - precision_14: 0.7559 - recall_14: 0.6152\n",
      "Epoch 14/500\n",
      "6000/6000 [==============================] - 1s 165us/step - loss: 0.5491 - precision_14: 0.7564 - recall_14: 0.6215\n",
      "Epoch 15/500\n",
      "6000/6000 [==============================] - 1s 162us/step - loss: 0.5438 - precision_14: 0.7571 - recall_14: 0.6276\n",
      "Epoch 16/500\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.5401 - precision_14: 0.7577 - recall_14: 0.6328\n",
      "Epoch 17/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.5411 - precision_14: 0.7586 - recall_14: 0.6381\n",
      "Epoch 18/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.5402 - precision_14: 0.7594 - recall_14: 0.6429\n",
      "Epoch 19/500\n",
      "6000/6000 [==============================] - 1s 161us/step - loss: 0.5420 - precision_14: 0.7600 - recall_14: 0.6471\n",
      "Epoch 20/500\n",
      "6000/6000 [==============================] - 1s 157us/step - loss: 0.5257 - precision_14: 0.7607 - recall_14: 0.6512\n",
      "Epoch 21/500\n",
      "6000/6000 [==============================] - 1s 160us/step - loss: 0.5399 - precision_14: 0.7614 - recall_14: 0.6552\n",
      "Epoch 22/500\n",
      "6000/6000 [==============================] - 1s 158us/step - loss: 0.5314 - precision_14: 0.7619 - recall_14: 0.6588\n",
      "Epoch 23/500\n",
      "6000/6000 [==============================] - 1s 150us/step - loss: 0.5205 - precision_14: 0.7624 - recall_14: 0.6620\n",
      "Epoch 24/500\n",
      "6000/6000 [==============================] - 1s 140us/step - loss: 0.5271 - precision_14: 0.7631 - recall_14: 0.6652\n",
      "Epoch 25/500\n",
      "6000/6000 [==============================] - 1s 153us/step - loss: 0.5217 - precision_14: 0.7638 - recall_14: 0.6683\n",
      "Epoch 26/500\n",
      "6000/6000 [==============================] - 1s 162us/step - loss: 0.5301 - precision_14: 0.7643 - recall_14: 0.6710\n",
      "Epoch 27/500\n",
      "6000/6000 [==============================] - 1s 169us/step - loss: 0.5272 - precision_14: 0.7647 - recall_14: 0.6737\n",
      "Epoch 28/500\n",
      "6000/6000 [==============================] - 1s 151us/step - loss: 0.5207 - precision_14: 0.7652 - recall_14: 0.6763\n",
      "Epoch 29/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.5029 - precision_14: 0.7662 - recall_14: 0.6791\n",
      "Epoch 30/500\n",
      "6000/6000 [==============================] - 1s 173us/step - loss: 0.5104 - precision_14: 0.7666 - recall_14: 0.6812\n",
      "Epoch 31/500\n",
      "6000/6000 [==============================] - 1s 151us/step - loss: 0.5139 - precision_14: 0.7669 - recall_14: 0.6834\n",
      "Epoch 32/500\n",
      "6000/6000 [==============================] - 1s 152us/step - loss: 0.5081 - precision_14: 0.7675 - recall_14: 0.6855\n",
      "Epoch 33/500\n",
      "6000/6000 [==============================] - 1s 159us/step - loss: 0.4989 - precision_14: 0.7680 - recall_14: 0.6876\n",
      "Epoch 34/500\n",
      "6000/6000 [==============================] - 1s 152us/step - loss: 0.4956 - precision_14: 0.7684 - recall_14: 0.6896\n",
      "Epoch 35/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.4975 - precision_14: 0.7691 - recall_14: 0.6917\n",
      "Epoch 36/500\n",
      "6000/6000 [==============================] - 1s 150us/step - loss: 0.5027 - precision_14: 0.7695 - recall_14: 0.6936\n",
      "Epoch 37/500\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.4919 - precision_14: 0.7701 - recall_14: 0.6954\n",
      "Epoch 38/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.5029 - precision_14: 0.7704 - recall_14: 0.6970\n",
      "Epoch 39/500\n",
      "6000/6000 [==============================] - 1s 157us/step - loss: 0.4869 - precision_14: 0.7709 - recall_14: 0.6988\n",
      "Epoch 40/500\n",
      "6000/6000 [==============================] - 1s 166us/step - loss: 0.4954 - precision_14: 0.7715 - recall_14: 0.7005\n",
      "Epoch 41/500\n",
      "6000/6000 [==============================] - 1s 162us/step - loss: 0.4952 - precision_14: 0.7718 - recall_14: 0.7020\n",
      "Epoch 42/500\n",
      "6000/6000 [==============================] - 1s 166us/step - loss: 0.4849 - precision_14: 0.7721 - recall_14: 0.7035\n",
      "Epoch 43/500\n",
      "6000/6000 [==============================] - 1s 161us/step - loss: 0.4793 - precision_14: 0.7726 - recall_14: 0.7051\n",
      "Epoch 44/500\n",
      "6000/6000 [==============================] - 1s 154us/step - loss: 0.4795 - precision_14: 0.7731 - recall_14: 0.7067\n",
      "Epoch 45/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.4749 - precision_14: 0.7736 - recall_14: 0.7082\n",
      "Epoch 46/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.4748 - precision_14: 0.7741 - recall_14: 0.7097\n",
      "Epoch 47/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.4814 - precision_14: 0.7744 - recall_14: 0.7110\n",
      "Epoch 48/500\n",
      "6000/6000 [==============================] - 1s 150us/step - loss: 0.4692 - precision_14: 0.7746 - recall_14: 0.7122\n",
      "Epoch 49/500\n",
      "6000/6000 [==============================] - 1s 151us/step - loss: 0.4612 - precision_14: 0.7750 - recall_14: 0.7134\n",
      "Epoch 50/500\n",
      "6000/6000 [==============================] - 1s 151us/step - loss: 0.4676 - precision_14: 0.7755 - recall_14: 0.7147\n",
      "Epoch 51/500\n",
      "6000/6000 [==============================] - 1s 155us/step - loss: 0.4540 - precision_14: 0.7760 - recall_14: 0.7161\n",
      "Epoch 52/500\n",
      "6000/6000 [==============================] - 1s 151us/step - loss: 0.4685 - precision_14: 0.7764 - recall_14: 0.7173\n",
      "Epoch 53/500\n",
      "6000/6000 [==============================] - 1s 154us/step - loss: 0.4729 - precision_14: 0.7768 - recall_14: 0.7184\n",
      "Epoch 54/500\n",
      "6000/6000 [==============================] - 1s 152us/step - loss: 0.4661 - precision_14: 0.7772 - recall_14: 0.7195\n",
      "Epoch 55/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.4555 - precision_14: 0.7775 - recall_14: 0.7205\n",
      "Epoch 56/500\n",
      "6000/6000 [==============================] - 1s 149us/step - loss: 0.4596 - precision_14: 0.7778 - recall_14: 0.7216\n",
      "Epoch 57/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.4664 - precision_14: 0.7782 - recall_14: 0.7226\n",
      "Epoch 58/500\n",
      "6000/6000 [==============================] - 1s 152us/step - loss: 0.4639 - precision_14: 0.7784 - recall_14: 0.7235\n",
      "Epoch 59/500\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.4434 - precision_14: 0.7788 - recall_14: 0.7245\n",
      "Epoch 60/500\n",
      "6000/6000 [==============================] - 1s 171us/step - loss: 0.4556 - precision_14: 0.7792 - recall_14: 0.7255\n",
      "Epoch 61/500\n",
      "6000/6000 [==============================] - 1s 158us/step - loss: 0.4598 - precision_14: 0.7795 - recall_14: 0.7264\n",
      "Epoch 62/500\n",
      "6000/6000 [==============================] - 1s 154us/step - loss: 0.4484 - precision_14: 0.7797 - recall_14: 0.7273\n",
      "Epoch 63/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 1s 151us/step - loss: 0.4537 - precision_14: 0.7801 - recall_14: 0.7282\n",
      "Epoch 64/500\n",
      "6000/6000 [==============================] - 1s 153us/step - loss: 0.4502 - precision_14: 0.7805 - recall_14: 0.7291\n",
      "Epoch 65/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.4438 - precision_14: 0.7808 - recall_14: 0.7300\n",
      "Epoch 66/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.4521 - precision_14: 0.7811 - recall_14: 0.7308\n",
      "Epoch 67/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.4477 - precision_14: 0.7815 - recall_14: 0.7317\n",
      "Epoch 68/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.4430 - precision_14: 0.7818 - recall_14: 0.7326\n",
      "Epoch 69/500\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.4478 - precision_14: 0.7822 - recall_14: 0.7335\n",
      "Epoch 70/500\n",
      "6000/6000 [==============================] - 1s 152us/step - loss: 0.4440 - precision_14: 0.7825 - recall_14: 0.7342\n",
      "Epoch 71/500\n",
      "6000/6000 [==============================] - 1s 162us/step - loss: 0.4535 - precision_14: 0.7829 - recall_14: 0.7350\n",
      "Epoch 72/500\n",
      "6000/6000 [==============================] - 1s 158us/step - loss: 0.4533 - precision_14: 0.7831 - recall_14: 0.7357\n",
      "Epoch 73/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.4462 - precision_14: 0.7834 - recall_14: 0.7364\n",
      "Epoch 74/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.4476 - precision_14: 0.7836 - recall_14: 0.7371\n",
      "Epoch 75/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.4322 - precision_14: 0.7840 - recall_14: 0.7378\n",
      "Epoch 76/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4320 - precision_14: 0.7843 - recall_14: 0.7385\n",
      "Epoch 77/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.4503 - precision_14: 0.7845 - recall_14: 0.7392\n",
      "Epoch 78/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.4458 - precision_14: 0.7848 - recall_14: 0.7398\n",
      "Epoch 79/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.4323 - precision_14: 0.7851 - recall_14: 0.7405\n",
      "Epoch 80/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4447 - precision_14: 0.7854 - recall_14: 0.7411\n",
      "Epoch 81/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.4324 - precision_14: 0.7856 - recall_14: 0.7417\n",
      "Epoch 82/500\n",
      "6000/6000 [==============================] - 1s 150us/step - loss: 0.4381 - precision_14: 0.7860 - recall_14: 0.7424\n",
      "Epoch 83/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.4389 - precision_14: 0.7863 - recall_14: 0.7430\n",
      "Epoch 84/500\n",
      "6000/6000 [==============================] - 1s 149us/step - loss: 0.4307 - precision_14: 0.7865 - recall_14: 0.7436\n",
      "Epoch 85/500\n",
      "6000/6000 [==============================] - 1s 150us/step - loss: 0.4287 - precision_14: 0.7869 - recall_14: 0.7443\n",
      "Epoch 86/500\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.4422 - precision_14: 0.7871 - recall_14: 0.7448\n",
      "Epoch 87/500\n",
      "6000/6000 [==============================] - 1s 149us/step - loss: 0.4411 - precision_14: 0.7872 - recall_14: 0.7453\n",
      "Epoch 88/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.4244 - precision_14: 0.7874 - recall_14: 0.7458\n",
      "Epoch 89/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.4324 - precision_14: 0.7878 - recall_14: 0.7464\n",
      "Epoch 90/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.4395 - precision_14: 0.7880 - recall_14: 0.7470\n",
      "Epoch 91/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.4414 - precision_14: 0.7882 - recall_14: 0.7475\n",
      "Epoch 92/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.4422 - precision_14: 0.7883 - recall_14: 0.7479\n",
      "Epoch 93/500\n",
      "6000/6000 [==============================] - 1s 159us/step - loss: 0.4327 - precision_14: 0.7885 - recall_14: 0.7484\n",
      "Epoch 94/500\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.4385 - precision_14: 0.7887 - recall_14: 0.7489\n",
      "Epoch 95/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.4343 - precision_14: 0.7889 - recall_14: 0.7493\n",
      "Epoch 96/500\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.4307 - precision_14: 0.7891 - recall_14: 0.7498\n",
      "Epoch 97/500\n",
      "6000/6000 [==============================] - 1s 149us/step - loss: 0.4336 - precision_14: 0.7893 - recall_14: 0.7503\n",
      "Epoch 98/500\n",
      "6000/6000 [==============================] - 1s 150us/step - loss: 0.4327 - precision_14: 0.7895 - recall_14: 0.7507\n",
      "Epoch 99/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.4311 - precision_14: 0.7897 - recall_14: 0.7512\n",
      "Epoch 100/500\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.4341 - precision_14: 0.7899 - recall_14: 0.7516\n",
      "Epoch 101/500\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.4341 - precision_14: 0.7901 - recall_14: 0.7521\n",
      "Epoch 102/500\n",
      "6000/6000 [==============================] - 1s 149us/step - loss: 0.4202 - precision_14: 0.7903 - recall_14: 0.7525\n",
      "Epoch 103/500\n",
      "6000/6000 [==============================] - 1s 152us/step - loss: 0.4281 - precision_14: 0.7905 - recall_14: 0.7530\n",
      "Epoch 104/500\n",
      "6000/6000 [==============================] - 1s 159us/step - loss: 0.4189 - precision_14: 0.7907 - recall_14: 0.7534\n",
      "Epoch 105/500\n",
      "6000/6000 [==============================] - 1s 149us/step - loss: 0.4345 - precision_14: 0.7909 - recall_14: 0.7538\n",
      "Epoch 106/500\n",
      "6000/6000 [==============================] - 1s 166us/step - loss: 0.4298 - precision_14: 0.7910 - recall_14: 0.7542\n",
      "Epoch 107/500\n",
      "6000/6000 [==============================] - 1s 164us/step - loss: 0.4241 - precision_14: 0.7913 - recall_14: 0.7546\n",
      "Epoch 108/500\n",
      "6000/6000 [==============================] - 1s 154us/step - loss: 0.4243 - precision_14: 0.7915 - recall_14: 0.7550\n",
      "Epoch 109/500\n",
      "6000/6000 [==============================] - 1s 151us/step - loss: 0.4212 - precision_14: 0.7917 - recall_14: 0.7555\n",
      "Epoch 110/500\n",
      "6000/6000 [==============================] - 1s 200us/step - loss: 0.4234 - precision_14: 0.7919 - recall_14: 0.7559\n",
      "Epoch 111/500\n",
      "6000/6000 [==============================] - 1s 191us/step - loss: 0.4239 - precision_14: 0.7921 - recall_14: 0.7563\n",
      "Epoch 112/500\n",
      "6000/6000 [==============================] - 1s 149us/step - loss: 0.4349 - precision_14: 0.7922 - recall_14: 0.7566\n",
      "Epoch 113/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.4244 - precision_14: 0.7923 - recall_14: 0.7569\n",
      "Epoch 114/500\n",
      "6000/6000 [==============================] - 1s 150us/step - loss: 0.4358 - precision_14: 0.7925 - recall_14: 0.7573\n",
      "Epoch 115/500\n",
      "6000/6000 [==============================] - 1s 159us/step - loss: 0.4290 - precision_14: 0.7926 - recall_14: 0.7576\n",
      "Epoch 116/500\n",
      "6000/6000 [==============================] - 1s 155us/step - loss: 0.4340 - precision_14: 0.7928 - recall_14: 0.7579\n",
      "Epoch 117/500\n",
      "6000/6000 [==============================] - 1s 155us/step - loss: 0.4203 - precision_14: 0.7929 - recall_14: 0.7582\n",
      "Epoch 118/500\n",
      "6000/6000 [==============================] - 1s 153us/step - loss: 0.4287 - precision_14: 0.7930 - recall_14: 0.7586\n",
      "Epoch 119/500\n",
      "6000/6000 [==============================] - 1s 174us/step - loss: 0.4141 - precision_14: 0.7932 - recall_14: 0.7589\n",
      "Epoch 120/500\n",
      "6000/6000 [==============================] - 1s 182us/step - loss: 0.4146 - precision_14: 0.7934 - recall_14: 0.7593\n",
      "Epoch 121/500\n",
      "6000/6000 [==============================] - 1s 170us/step - loss: 0.4177 - precision_14: 0.7936 - recall_14: 0.7597\n",
      "Epoch 122/500\n",
      "6000/6000 [==============================] - 1s 151us/step - loss: 0.4278 - precision_14: 0.7938 - recall_14: 0.7600\n",
      "Epoch 123/500\n",
      "6000/6000 [==============================] - 1s 149us/step - loss: 0.4291 - precision_14: 0.7939 - recall_14: 0.7603\n",
      "Epoch 124/500\n",
      "6000/6000 [==============================] - 1s 178us/step - loss: 0.4186 - precision_14: 0.7941 - recall_14: 0.7606\n",
      "Epoch 125/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 1s 150us/step - loss: 0.4229 - precision_14: 0.7943 - recall_14: 0.7610\n",
      "Epoch 126/500\n",
      "6000/6000 [==============================] - 1s 158us/step - loss: 0.4130 - precision_14: 0.7945 - recall_14: 0.7613\n",
      "Epoch 127/500\n",
      "6000/6000 [==============================] - 1s 160us/step - loss: 0.4295 - precision_14: 0.7946 - recall_14: 0.7617\n",
      "Epoch 128/500\n",
      "6000/6000 [==============================] - 1s 180us/step - loss: 0.4231 - precision_14: 0.7948 - recall_14: 0.7620\n",
      "Epoch 129/500\n",
      "6000/6000 [==============================] - 1s 184us/step - loss: 0.4268 - precision_14: 0.7949 - recall_14: 0.7623\n",
      "Epoch 130/500\n",
      "6000/6000 [==============================] - 1s 177us/step - loss: 0.4185 - precision_14: 0.7951 - recall_14: 0.7626\n",
      "Epoch 131/500\n",
      "6000/6000 [==============================] - 1s 162us/step - loss: 0.4281 - precision_14: 0.7952 - recall_14: 0.7629\n",
      "Epoch 132/500\n",
      "6000/6000 [==============================] - 1s 171us/step - loss: 0.4268 - precision_14: 0.7953 - recall_14: 0.7631\n",
      "Epoch 133/500\n",
      "6000/6000 [==============================] - 1s 170us/step - loss: 0.4128 - precision_14: 0.7955 - recall_14: 0.7634\n",
      "Epoch 134/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.4312 - precision_14: 0.7956 - recall_14: 0.7637\n",
      "Epoch 135/500\n",
      "6000/6000 [==============================] - 1s 150us/step - loss: 0.4213 - precision_14: 0.7957 - recall_14: 0.7639\n",
      "Epoch 136/500\n",
      "6000/6000 [==============================] - 1s 151us/step - loss: 0.4207 - precision_14: 0.7958 - recall_14: 0.7642\n",
      "Epoch 137/500\n",
      "6000/6000 [==============================] - 1s 150us/step - loss: 0.4186 - precision_14: 0.7960 - recall_14: 0.7645\n",
      "Epoch 138/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.4240 - precision_14: 0.7961 - recall_14: 0.7647\n",
      "Epoch 139/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.4284 - precision_14: 0.7962 - recall_14: 0.7650\n",
      "Epoch 140/500\n",
      "6000/6000 [==============================] - 1s 151us/step - loss: 0.4225 - precision_14: 0.7963 - recall_14: 0.7652\n",
      "Epoch 141/500\n",
      "6000/6000 [==============================] - 1s 168us/step - loss: 0.4162 - precision_14: 0.7965 - recall_14: 0.7655\n",
      "Epoch 142/500\n",
      "6000/6000 [==============================] - 1s 163us/step - loss: 0.4104 - precision_14: 0.7967 - recall_14: 0.7658\n",
      "Epoch 143/500\n",
      "6000/6000 [==============================] - 1s 154us/step - loss: 0.4200 - precision_14: 0.7968 - recall_14: 0.7661\n",
      "Epoch 144/500\n",
      "6000/6000 [==============================] - 1s 171us/step - loss: 0.4218 - precision_14: 0.7969 - recall_14: 0.7663\n",
      "Epoch 145/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.4182 - precision_14: 0.7970 - recall_14: 0.7666\n",
      "Epoch 146/500\n",
      "6000/6000 [==============================] - 1s 138us/step - loss: 0.4333 - precision_14: 0.7971 - recall_14: 0.7668\n",
      "Epoch 147/500\n",
      "6000/6000 [==============================] - 1s 137us/step - loss: 0.4184 - precision_14: 0.7972 - recall_14: 0.7670\n",
      "Epoch 148/500\n",
      "6000/6000 [==============================] - 1s 139us/step - loss: 0.4265 - precision_14: 0.7973 - recall_14: 0.7672\n",
      "Epoch 149/500\n",
      "6000/6000 [==============================] - 1s 140us/step - loss: 0.4127 - precision_14: 0.7974 - recall_14: 0.7674\n",
      "Epoch 150/500\n",
      "6000/6000 [==============================] - 1s 138us/step - loss: 0.4209 - precision_14: 0.7975 - recall_14: 0.7676\n",
      "Epoch 151/500\n",
      "6000/6000 [==============================] - 1s 140us/step - loss: 0.4224 - precision_14: 0.7976 - recall_14: 0.7679\n",
      "Epoch 152/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.4133 - precision_14: 0.7977 - recall_14: 0.7681\n",
      "Epoch 153/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.4231 - precision_14: 0.7979 - recall_14: 0.7683\n",
      "Epoch 154/500\n",
      "6000/6000 [==============================] - 1s 154us/step - loss: 0.4155 - precision_14: 0.7979 - recall_14: 0.7685\n",
      "Epoch 155/500\n",
      "6000/6000 [==============================] - 1s 156us/step - loss: 0.4162 - precision_14: 0.7980 - recall_14: 0.7687\n",
      "Epoch 156/500\n",
      "6000/6000 [==============================] - 1s 156us/step - loss: 0.4177 - precision_14: 0.7981 - recall_14: 0.7689\n",
      "Epoch 157/500\n",
      "6000/6000 [==============================] - 1s 155us/step - loss: 0.4200 - precision_14: 0.7982 - recall_14: 0.7691\n",
      "Epoch 158/500\n",
      "6000/6000 [==============================] - 1s 173us/step - loss: 0.4225 - precision_14: 0.7983 - recall_14: 0.7693\n",
      "Epoch 159/500\n",
      "6000/6000 [==============================] - 1s 174us/step - loss: 0.4129 - precision_14: 0.7984 - recall_14: 0.7695\n",
      "Epoch 160/500\n",
      "6000/6000 [==============================] - 1s 151us/step - loss: 0.4204 - precision_14: 0.7985 - recall_14: 0.7697\n",
      "Epoch 161/500\n",
      "6000/6000 [==============================] - 1s 140us/step - loss: 0.4207 - precision_14: 0.7986 - recall_14: 0.7699\n",
      "Epoch 162/500\n",
      "6000/6000 [==============================] - 1s 152us/step - loss: 0.4151 - precision_14: 0.7987 - recall_14: 0.7701\n",
      "Epoch 163/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4283 - precision_14: 0.7988 - recall_14: 0.7703\n",
      "Epoch 164/500\n",
      "6000/6000 [==============================] - 1s 151us/step - loss: 0.4225 - precision_14: 0.7988 - recall_14: 0.7704\n",
      "Epoch 165/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.4180 - precision_14: 0.7989 - recall_14: 0.7706\n",
      "Epoch 166/500\n",
      "6000/6000 [==============================] - 1s 141us/step - loss: 0.4106 - precision_14: 0.7990 - recall_14: 0.7708\n",
      "Epoch 167/500\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.4111 - precision_14: 0.7991 - recall_14: 0.7710\n",
      "Epoch 168/500\n",
      "6000/6000 [==============================] - 1s 156us/step - loss: 0.4144 - precision_14: 0.7992 - recall_14: 0.7713\n",
      "Epoch 169/500\n",
      "6000/6000 [==============================] - 1s 154us/step - loss: 0.4245 - precision_14: 0.7993 - recall_14: 0.7714\n",
      "Epoch 170/500\n",
      "6000/6000 [==============================] - 1s 155us/step - loss: 0.4296 - precision_14: 0.7994 - recall_14: 0.7716\n",
      "Epoch 171/500\n",
      "6000/6000 [==============================] - 1s 150us/step - loss: 0.4234 - precision_14: 0.7994 - recall_14: 0.7718\n",
      "Epoch 172/500\n",
      "6000/6000 [==============================] - 1s 140us/step - loss: 0.4126 - precision_14: 0.7995 - recall_14: 0.7719\n",
      "Epoch 173/500\n",
      "6000/6000 [==============================] - 1s 188us/step - loss: 0.4202 - precision_14: 0.7996 - recall_14: 0.7721\n",
      "Epoch 174/500\n",
      "6000/6000 [==============================] - 1s 176us/step - loss: 0.4136 - precision_14: 0.7997 - recall_14: 0.7723\n",
      "Epoch 175/500\n",
      "6000/6000 [==============================] - 1s 172us/step - loss: 0.4217 - precision_14: 0.7998 - recall_14: 0.7725\n",
      "Epoch 176/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.4175 - precision_14: 0.7999 - recall_14: 0.7726\n",
      "Epoch 177/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.4040 - precision_14: 0.8000 - recall_14: 0.7728\n",
      "Epoch 178/500\n",
      "6000/6000 [==============================] - 1s 139us/step - loss: 0.4198 - precision_14: 0.8000 - recall_14: 0.7730\n",
      "Epoch 179/500\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.4291 - precision_14: 0.8001 - recall_14: 0.7731\n",
      "Epoch 180/500\n",
      "6000/6000 [==============================] - 1s 150us/step - loss: 0.4123 - precision_14: 0.8002 - recall_14: 0.7733\n",
      "Epoch 181/500\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.4156 - precision_14: 0.8003 - recall_14: 0.7735\n",
      "Epoch 182/500\n",
      "6000/6000 [==============================] - 1s 179us/step - loss: 0.4046 - precision_14: 0.8004 - recall_14: 0.7737\n",
      "Epoch 183/500\n",
      "6000/6000 [==============================] - 1s 171us/step - loss: 0.4125 - precision_14: 0.8005 - recall_14: 0.7739\n",
      "Epoch 184/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4239 - precision_14: 0.8006 - recall_14: 0.7740\n",
      "Epoch 185/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.4190 - precision_14: 0.8006 - recall_14: 0.7742\n",
      "Epoch 186/500\n",
      "6000/6000 [==============================] - 1s 156us/step - loss: 0.4136 - precision_14: 0.8007 - recall_14: 0.7743\n",
      "Epoch 187/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4206 - precision_14: 0.8008 - recall_14: 0.7745\n",
      "Epoch 188/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.4147 - precision_14: 0.8008 - recall_14: 0.7746\n",
      "Epoch 189/500\n",
      "6000/6000 [==============================] - 1s 156us/step - loss: 0.4129 - precision_14: 0.8009 - recall_14: 0.7747\n",
      "Epoch 190/500\n",
      "6000/6000 [==============================] - 1s 154us/step - loss: 0.4124 - precision_14: 0.8010 - recall_14: 0.7749\n",
      "Epoch 191/500\n",
      "6000/6000 [==============================] - 1s 158us/step - loss: 0.4185 - precision_14: 0.8011 - recall_14: 0.7751\n",
      "Epoch 192/500\n",
      "6000/6000 [==============================] - 1s 140us/step - loss: 0.4059 - precision_14: 0.8012 - recall_14: 0.7752\n",
      "Epoch 193/500\n",
      "6000/6000 [==============================] - 1s 137us/step - loss: 0.4232 - precision_14: 0.8012 - recall_14: 0.7754\n",
      "Epoch 194/500\n",
      "6000/6000 [==============================] - 1s 138us/step - loss: 0.4149 - precision_14: 0.8013 - recall_14: 0.7755\n",
      "Epoch 195/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.4126 - precision_14: 0.8014 - recall_14: 0.7757\n",
      "Epoch 196/500\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.4176 - precision_14: 0.8014 - recall_14: 0.7758\n",
      "Epoch 197/500\n",
      "6000/6000 [==============================] - 1s 163us/step - loss: 0.4164 - precision_14: 0.8015 - recall_14: 0.7759\n",
      "Epoch 198/500\n",
      "6000/6000 [==============================] - 1s 155us/step - loss: 0.4086 - precision_14: 0.8016 - recall_14: 0.7761\n",
      "Epoch 199/500\n",
      "6000/6000 [==============================] - 1s 156us/step - loss: 0.4183 - precision_14: 0.8017 - recall_14: 0.7762\n",
      "Epoch 200/500\n",
      "6000/6000 [==============================] - 1s 154us/step - loss: 0.4284 - precision_14: 0.8017 - recall_14: 0.7764\n",
      "Epoch 201/500\n",
      "6000/6000 [==============================] - 1s 165us/step - loss: 0.4015 - precision_14: 0.8018 - recall_14: 0.7765\n",
      "Epoch 202/500\n",
      "6000/6000 [==============================] - 1s 177us/step - loss: 0.4148 - precision_14: 0.8019 - recall_14: 0.7767\n",
      "Epoch 203/500\n",
      "6000/6000 [==============================] - 1s 156us/step - loss: 0.4200 - precision_14: 0.8020 - recall_14: 0.7768\n",
      "Epoch 204/500\n",
      "6000/6000 [==============================] - 1s 160us/step - loss: 0.4152 - precision_14: 0.8020 - recall_14: 0.7769\n",
      "Epoch 205/500\n",
      "6000/6000 [==============================] - 1s 154us/step - loss: 0.4153 - precision_14: 0.8021 - recall_14: 0.7771\n",
      "Epoch 206/500\n",
      "6000/6000 [==============================] - 1s 153us/step - loss: 0.4108 - precision_14: 0.8021 - recall_14: 0.7772\n",
      "Epoch 207/500\n",
      "6000/6000 [==============================] - 1s 152us/step - loss: 0.4133 - precision_14: 0.8022 - recall_14: 0.7773\n",
      "Epoch 208/500\n",
      "6000/6000 [==============================] - 1s 149us/step - loss: 0.4101 - precision_14: 0.8023 - recall_14: 0.7774\n",
      "Epoch 209/500\n",
      "6000/6000 [==============================] - 1s 205us/step - loss: 0.4203 - precision_14: 0.8023 - recall_14: 0.7776\n",
      "Epoch 210/500\n",
      "6000/6000 [==============================] - 1s 178us/step - loss: 0.4110 - precision_14: 0.8024 - recall_14: 0.7777\n",
      "Epoch 211/500\n",
      "6000/6000 [==============================] - 1s 156us/step - loss: 0.4154 - precision_14: 0.8024 - recall_14: 0.7778\n",
      "Epoch 212/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.4121 - precision_14: 0.8025 - recall_14: 0.7779\n",
      "Epoch 213/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4178 - precision_14: 0.8025 - recall_14: 0.7780\n",
      "Epoch 214/500\n",
      "6000/6000 [==============================] - 1s 141us/step - loss: 0.4172 - precision_14: 0.8026 - recall_14: 0.7781\n",
      "Epoch 215/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.4157 - precision_14: 0.8026 - recall_14: 0.7783\n",
      "Epoch 216/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4150 - precision_14: 0.8027 - recall_14: 0.7784\n",
      "Epoch 217/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.4042 - precision_14: 0.8027 - recall_14: 0.7785\n",
      "Epoch 218/500\n",
      "6000/6000 [==============================] - 1s 159us/step - loss: 0.4130 - precision_14: 0.8028 - recall_14: 0.7786\n",
      "Epoch 219/500\n",
      "6000/6000 [==============================] - 1s 159us/step - loss: 0.4167 - precision_14: 0.8029 - recall_14: 0.7787\n",
      "Epoch 220/500\n",
      "6000/6000 [==============================] - 1s 161us/step - loss: 0.4165 - precision_14: 0.8029 - recall_14: 0.7788\n",
      "Epoch 221/500\n",
      "6000/6000 [==============================] - 1s 166us/step - loss: 0.4092 - precision_14: 0.8029 - recall_14: 0.7789\n",
      "Epoch 222/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.4028 - precision_14: 0.8030 - recall_14: 0.7791\n",
      "Epoch 223/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4104 - precision_14: 0.8031 - recall_14: 0.7792\n",
      "Epoch 224/500\n",
      "6000/6000 [==============================] - 1s 141us/step - loss: 0.4245 - precision_14: 0.8031 - recall_14: 0.7793\n",
      "Epoch 225/500\n",
      "6000/6000 [==============================] - 1s 140us/step - loss: 0.4249 - precision_14: 0.8032 - recall_14: 0.7794\n",
      "Epoch 226/500\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.4069 - precision_14: 0.8032 - recall_14: 0.7795\n",
      "Epoch 227/500\n",
      "6000/6000 [==============================] - 1s 149us/step - loss: 0.4016 - precision_14: 0.8033 - recall_14: 0.7796\n",
      "Epoch 228/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.4013 - precision_14: 0.8033 - recall_14: 0.7797\n",
      "Epoch 229/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.4171 - precision_14: 0.8034 - recall_14: 0.7799\n",
      "Epoch 230/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.4083 - precision_14: 0.8034 - recall_14: 0.7800\n",
      "Epoch 231/500\n",
      "6000/6000 [==============================] - 1s 157us/step - loss: 0.4068 - precision_14: 0.8035 - recall_14: 0.7801\n",
      "Epoch 232/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.4037 - precision_14: 0.8035 - recall_14: 0.7802\n",
      "Epoch 233/500\n",
      "6000/6000 [==============================] - 1s 149us/step - loss: 0.4135 - precision_14: 0.8036 - recall_14: 0.7803\n",
      "Epoch 234/500\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.4171 - precision_14: 0.8036 - recall_14: 0.7804\n",
      "Epoch 235/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.4053 - precision_14: 0.8037 - recall_14: 0.7805\n",
      "Epoch 236/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.4160 - precision_14: 0.8037 - recall_14: 0.7806\n",
      "Epoch 237/500\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.3930 - precision_14: 0.8038 - recall_14: 0.7808\n",
      "Epoch 238/500\n",
      "6000/6000 [==============================] - 1s 181us/step - loss: 0.4198 - precision_14: 0.8039 - recall_14: 0.7809\n",
      "Epoch 239/500\n",
      "6000/6000 [==============================] - 1s 162us/step - loss: 0.4273 - precision_14: 0.8040 - recall_14: 0.7810\n",
      "Epoch 240/500\n",
      "6000/6000 [==============================] - 1s 159us/step - loss: 0.4127 - precision_14: 0.8040 - recall_14: 0.7811\n",
      "Epoch 241/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.4153 - precision_14: 0.8041 - recall_14: 0.7812\n",
      "Epoch 242/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.4200 - precision_14: 0.8041 - recall_14: 0.7813\n",
      "Epoch 243/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.4140 - precision_14: 0.8041 - recall_14: 0.7814\n",
      "Epoch 244/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.4132 - precision_14: 0.8042 - recall_14: 0.7814\n",
      "Epoch 245/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.4056 - precision_14: 0.8042 - recall_14: 0.7815\n",
      "Epoch 246/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4139 - precision_14: 0.8043 - recall_14: 0.7816\n",
      "Epoch 247/500\n",
      "6000/6000 [==============================] - 1s 149us/step - loss: 0.4135 - precision_14: 0.8043 - recall_14: 0.7817\n",
      "Epoch 248/500\n",
      "6000/6000 [==============================] - 1s 158us/step - loss: 0.4175 - precision_14: 0.8043 - recall_14: 0.7818\n",
      "Epoch 249/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 1s 159us/step - loss: 0.4086 - precision_14: 0.8044 - recall_14: 0.7819\n",
      "Epoch 250/500\n",
      "6000/6000 [==============================] - 1s 139us/step - loss: 0.4075 - precision_14: 0.8044 - recall_14: 0.7820\n",
      "Epoch 251/500\n",
      "6000/6000 [==============================] - 1s 139us/step - loss: 0.4056 - precision_14: 0.8045 - recall_14: 0.7821\n",
      "Epoch 252/500\n",
      "6000/6000 [==============================] - 1s 154us/step - loss: 0.4175 - precision_14: 0.8045 - recall_14: 0.7822\n",
      "Epoch 253/500\n",
      "6000/6000 [==============================] - 1s 164us/step - loss: 0.4170 - precision_14: 0.8046 - recall_14: 0.7823\n",
      "Epoch 254/500\n",
      "6000/6000 [==============================] - 1s 163us/step - loss: 0.4056 - precision_14: 0.8046 - recall_14: 0.7824\n",
      "Epoch 255/500\n",
      "6000/6000 [==============================] - 1s 165us/step - loss: 0.4153 - precision_14: 0.8047 - recall_14: 0.7824\n",
      "Epoch 256/500\n",
      "6000/6000 [==============================] - 1s 186us/step - loss: 0.4177 - precision_14: 0.8047 - recall_14: 0.7825\n",
      "Epoch 257/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.4179 - precision_14: 0.8047 - recall_14: 0.7826\n",
      "Epoch 258/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.4098 - precision_14: 0.8048 - recall_14: 0.7827\n",
      "Epoch 259/500\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.4170 - precision_14: 0.8048 - recall_14: 0.7828\n",
      "Epoch 260/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.4056 - precision_14: 0.8048 - recall_14: 0.7828\n",
      "Epoch 261/500\n",
      "6000/6000 [==============================] - 1s 153us/step - loss: 0.4206 - precision_14: 0.8049 - recall_14: 0.7829\n",
      "Epoch 262/500\n",
      "6000/6000 [==============================] - 1s 156us/step - loss: 0.4122 - precision_14: 0.8049 - recall_14: 0.7830\n",
      "Epoch 263/500\n",
      "6000/6000 [==============================] - 1s 152us/step - loss: 0.4058 - precision_14: 0.8050 - recall_14: 0.7831\n",
      "Epoch 264/500\n",
      "6000/6000 [==============================] - 1s 154us/step - loss: 0.4224 - precision_14: 0.8050 - recall_14: 0.7832\n",
      "Epoch 265/500\n",
      "6000/6000 [==============================] - 1s 159us/step - loss: 0.3970 - precision_14: 0.8051 - recall_14: 0.7833\n",
      "Epoch 266/500\n",
      "6000/6000 [==============================] - 1s 166us/step - loss: 0.4134 - precision_14: 0.8051 - recall_14: 0.7834\n",
      "Epoch 267/500\n",
      "6000/6000 [==============================] - 1s 151us/step - loss: 0.4057 - precision_14: 0.8052 - recall_14: 0.7835\n",
      "Epoch 268/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.3889 - precision_14: 0.8052 - recall_14: 0.7836\n",
      "Epoch 269/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4211 - precision_14: 0.8053 - recall_14: 0.7837\n",
      "Epoch 270/500\n",
      "6000/6000 [==============================] - 1s 142us/step - loss: 0.4006 - precision_14: 0.8054 - recall_14: 0.7838\n",
      "Epoch 271/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.4018 - precision_14: 0.8054 - recall_14: 0.7839\n",
      "Epoch 272/500\n",
      "6000/6000 [==============================] - 1s 142us/step - loss: 0.4074 - precision_14: 0.8055 - recall_14: 0.7840\n",
      "Epoch 273/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.4018 - precision_14: 0.8055 - recall_14: 0.7841\n",
      "Epoch 274/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.4136 - precision_14: 0.8056 - recall_14: 0.7842\n",
      "Epoch 275/500\n",
      "6000/6000 [==============================] - 1s 153us/step - loss: 0.4068 - precision_14: 0.8056 - recall_14: 0.7843\n",
      "Epoch 276/500\n",
      "6000/6000 [==============================] - 1s 168us/step - loss: 0.4050 - precision_14: 0.8056 - recall_14: 0.7844\n",
      "Epoch 277/500\n",
      "6000/6000 [==============================] - 1s 192us/step - loss: 0.4100 - precision_14: 0.8057 - recall_14: 0.7845\n",
      "Epoch 278/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.4091 - precision_14: 0.8057 - recall_14: 0.7845\n",
      "Epoch 279/500\n",
      "6000/6000 [==============================] - 1s 139us/step - loss: 0.4117 - precision_14: 0.8058 - recall_14: 0.7846\n",
      "Epoch 280/500\n",
      "6000/6000 [==============================] - 1s 140us/step - loss: 0.4157 - precision_14: 0.8058 - recall_14: 0.7847\n",
      "Epoch 281/500\n",
      "6000/6000 [==============================] - 1s 142us/step - loss: 0.4164 - precision_14: 0.8058 - recall_14: 0.7848\n",
      "Epoch 282/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.4109 - precision_14: 0.8059 - recall_14: 0.7848\n",
      "Epoch 283/500\n",
      "6000/6000 [==============================] - 1s 155us/step - loss: 0.4158 - precision_14: 0.8059 - recall_14: 0.7849\n",
      "Epoch 284/500\n",
      "6000/6000 [==============================] - 1s 166us/step - loss: 0.4097 - precision_14: 0.8060 - recall_14: 0.7850\n",
      "Epoch 285/500\n",
      "6000/6000 [==============================] - 1s 166us/step - loss: 0.4154 - precision_14: 0.8060 - recall_14: 0.7851\n",
      "Epoch 286/500\n",
      "6000/6000 [==============================] - 1s 163us/step - loss: 0.4168 - precision_14: 0.8061 - recall_14: 0.7852\n",
      "Epoch 287/500\n",
      "6000/6000 [==============================] - 1s 158us/step - loss: 0.4145 - precision_14: 0.8061 - recall_14: 0.7852\n",
      "Epoch 288/500\n",
      "6000/6000 [==============================] - 1s 152us/step - loss: 0.4119 - precision_14: 0.8061 - recall_14: 0.7853\n",
      "Epoch 289/500\n",
      "6000/6000 [==============================] - 1s 157us/step - loss: 0.3957 - precision_14: 0.8062 - recall_14: 0.7854\n",
      "Epoch 290/500\n",
      "6000/6000 [==============================] - 1s 163us/step - loss: 0.4099 - precision_14: 0.8063 - recall_14: 0.7855\n",
      "Epoch 291/500\n",
      "6000/6000 [==============================] - 1s 189us/step - loss: 0.4109 - precision_14: 0.8063 - recall_14: 0.7856\n",
      "Epoch 292/500\n",
      "6000/6000 [==============================] - 1s 152us/step - loss: 0.3998 - precision_14: 0.8064 - recall_14: 0.7857\n",
      "Epoch 293/500\n",
      "6000/6000 [==============================] - 1s 141us/step - loss: 0.4010 - precision_14: 0.8064 - recall_14: 0.7858\n",
      "Epoch 294/500\n",
      "6000/6000 [==============================] - 1s 140us/step - loss: 0.4053 - precision_14: 0.8065 - recall_14: 0.7858\n",
      "Epoch 295/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.4030 - precision_14: 0.8065 - recall_14: 0.7859\n",
      "Epoch 296/500\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.4125 - precision_14: 0.8065 - recall_14: 0.7860\n",
      "Epoch 297/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.4055 - precision_14: 0.8066 - recall_14: 0.7861\n",
      "Epoch 298/500\n",
      "6000/6000 [==============================] - 1s 140us/step - loss: 0.4082 - precision_14: 0.8066 - recall_14: 0.7861\n",
      "Epoch 299/500\n",
      "6000/6000 [==============================] - 1s 149us/step - loss: 0.4182 - precision_14: 0.8066 - recall_14: 0.7862\n",
      "Epoch 300/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.4101 - precision_14: 0.8067 - recall_14: 0.7862\n",
      "Epoch 301/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4190 - precision_14: 0.8067 - recall_14: 0.7863\n",
      "Epoch 302/500\n",
      "6000/6000 [==============================] - 1s 182us/step - loss: 0.4010 - precision_14: 0.8067 - recall_14: 0.7864\n",
      "Epoch 303/500\n",
      "6000/6000 [==============================] - 1s 161us/step - loss: 0.4141 - precision_14: 0.8068 - recall_14: 0.7865\n",
      "Epoch 304/500\n",
      "6000/6000 [==============================] - 1s 159us/step - loss: 0.4210 - precision_14: 0.8068 - recall_14: 0.7865\n",
      "Epoch 305/500\n",
      "6000/6000 [==============================] - 1s 160us/step - loss: 0.4045 - precision_14: 0.8068 - recall_14: 0.7866\n",
      "Epoch 306/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4029 - precision_14: 0.8068 - recall_14: 0.7866\n",
      "Epoch 307/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.4165 - precision_14: 0.8069 - recall_14: 0.7867\n",
      "Epoch 308/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4057 - precision_14: 0.8069 - recall_14: 0.7868\n",
      "Epoch 309/500\n",
      "6000/6000 [==============================] - 1s 140us/step - loss: 0.4176 - precision_14: 0.8069 - recall_14: 0.7868\n",
      "Epoch 310/500\n",
      "6000/6000 [==============================] - 1s 151us/step - loss: 0.4099 - precision_14: 0.8070 - recall_14: 0.7869\n",
      "Epoch 311/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.4001 - precision_14: 0.8070 - recall_14: 0.7869\n",
      "Epoch 312/500\n",
      "6000/6000 [==============================] - ETA: 0s - loss: 0.3924 - precision_14: 0.8070 - recall_14: 0.78 - 1s 161us/step - loss: 0.3936 - precision_14: 0.8070 - recall_14: 0.7870\n",
      "Epoch 313/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.4063 - precision_14: 0.8071 - recall_14: 0.7871\n",
      "Epoch 314/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.4056 - precision_14: 0.8071 - recall_14: 0.7872\n",
      "Epoch 315/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4123 - precision_14: 0.8072 - recall_14: 0.7872\n",
      "Epoch 316/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4132 - precision_14: 0.8072 - recall_14: 0.7873\n",
      "Epoch 317/500\n",
      "6000/6000 [==============================] - 1s 170us/step - loss: 0.4011 - precision_14: 0.8072 - recall_14: 0.7874\n",
      "Epoch 318/500\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.4150 - precision_14: 0.8073 - recall_14: 0.7874\n",
      "Epoch 319/500\n",
      "6000/6000 [==============================] - 1s 165us/step - loss: 0.4035 - precision_14: 0.8073 - recall_14: 0.7875\n",
      "Epoch 320/500\n",
      "6000/6000 [==============================] - 1s 157us/step - loss: 0.4058 - precision_14: 0.8073 - recall_14: 0.7876\n",
      "Epoch 321/500\n",
      "6000/6000 [==============================] - 1s 158us/step - loss: 0.4097 - precision_14: 0.8074 - recall_14: 0.7876\n",
      "Epoch 322/500\n",
      "6000/6000 [==============================] - 1s 152us/step - loss: 0.3929 - precision_14: 0.8074 - recall_14: 0.7877\n",
      "Epoch 323/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.4093 - precision_14: 0.8075 - recall_14: 0.7878\n",
      "Epoch 324/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4148 - precision_14: 0.8075 - recall_14: 0.7878\n",
      "Epoch 325/500\n",
      "6000/6000 [==============================] - 1s 159us/step - loss: 0.4059 - precision_14: 0.8075 - recall_14: 0.7879\n",
      "Epoch 326/500\n",
      "6000/6000 [==============================] - 1s 159us/step - loss: 0.4091 - precision_14: 0.8075 - recall_14: 0.7879\n",
      "Epoch 327/500\n",
      "6000/6000 [==============================] - 1s 191us/step - loss: 0.3973 - precision_14: 0.8076 - recall_14: 0.7880\n",
      "Epoch 328/500\n",
      "6000/6000 [==============================] - 1s 197us/step - loss: 0.4044 - precision_14: 0.8076 - recall_14: 0.7881\n",
      "Epoch 329/500\n",
      "6000/6000 [==============================] - 1s 172us/step - loss: 0.4067 - precision_14: 0.8076 - recall_14: 0.7881\n",
      "Epoch 330/500\n",
      "6000/6000 [==============================] - 1s 169us/step - loss: 0.4094 - precision_14: 0.8077 - recall_14: 0.7882\n",
      "Epoch 331/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.3989 - precision_14: 0.8077 - recall_14: 0.7883\n",
      "Epoch 332/500\n",
      "6000/6000 [==============================] - 1s 157us/step - loss: 0.3995 - precision_14: 0.8077 - recall_14: 0.7883\n",
      "Epoch 333/500\n",
      "6000/6000 [==============================] - 1s 182us/step - loss: 0.4001 - precision_14: 0.8078 - recall_14: 0.7884\n",
      "Epoch 334/500\n",
      "6000/6000 [==============================] - 1s 181us/step - loss: 0.4099 - precision_14: 0.8078 - recall_14: 0.7885\n",
      "Epoch 335/500\n",
      "6000/6000 [==============================] - 1s 183us/step - loss: 0.4137 - precision_14: 0.8078 - recall_14: 0.7885\n",
      "Epoch 336/500\n",
      "6000/6000 [==============================] - 1s 173us/step - loss: 0.4076 - precision_14: 0.8079 - recall_14: 0.7886\n",
      "Epoch 337/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.4033 - precision_14: 0.8079 - recall_14: 0.7886\n",
      "Epoch 338/500\n",
      "6000/6000 [==============================] - 1s 173us/step - loss: 0.4124 - precision_14: 0.8079 - recall_14: 0.7887\n",
      "Epoch 339/500\n",
      "6000/6000 [==============================] - 1s 176us/step - loss: 0.3997 - precision_14: 0.8079 - recall_14: 0.7887\n",
      "Epoch 340/500\n",
      "6000/6000 [==============================] - 1s 174us/step - loss: 0.4069 - precision_14: 0.8080 - recall_14: 0.7888\n",
      "Epoch 341/500\n",
      "6000/6000 [==============================] - 1s 169us/step - loss: 0.4007 - precision_14: 0.8080 - recall_14: 0.7889\n",
      "Epoch 342/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.3995 - precision_14: 0.8080 - recall_14: 0.7889\n",
      "Epoch 343/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.4114 - precision_14: 0.8081 - recall_14: 0.7890\n",
      "Epoch 344/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.4036 - precision_14: 0.8081 - recall_14: 0.7891\n",
      "Epoch 345/500\n",
      "6000/6000 [==============================] - 1s 150us/step - loss: 0.4080 - precision_14: 0.8081 - recall_14: 0.7891\n",
      "Epoch 346/500\n",
      "6000/6000 [==============================] - 1s 150us/step - loss: 0.4099 - precision_14: 0.8082 - recall_14: 0.7892\n",
      "Epoch 347/500\n",
      "6000/6000 [==============================] - 1s 149us/step - loss: 0.4074 - precision_14: 0.8082 - recall_14: 0.7892\n",
      "Epoch 348/500\n",
      "6000/6000 [==============================] - 1s 139us/step - loss: 0.4011 - precision_14: 0.8082 - recall_14: 0.7893\n",
      "Epoch 349/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.3981 - precision_14: 0.8082 - recall_14: 0.7893\n",
      "Epoch 350/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.4076 - precision_14: 0.8083 - recall_14: 0.7894\n",
      "Epoch 351/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.4033 - precision_14: 0.8083 - recall_14: 0.7894\n",
      "Epoch 352/500\n",
      "6000/6000 [==============================] - 1s 155us/step - loss: 0.4147 - precision_14: 0.8083 - recall_14: 0.7895\n",
      "Epoch 353/500\n",
      "6000/6000 [==============================] - 1s 153us/step - loss: 0.4063 - precision_14: 0.8084 - recall_14: 0.7895\n",
      "Epoch 354/500\n",
      "6000/6000 [==============================] - 1s 142us/step - loss: 0.4142 - precision_14: 0.8084 - recall_14: 0.7896\n",
      "Epoch 355/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4027 - precision_14: 0.8084 - recall_14: 0.7896\n",
      "Epoch 356/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.3990 - precision_14: 0.8084 - recall_14: 0.7897\n",
      "Epoch 357/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4162 - precision_14: 0.8084 - recall_14: 0.7897\n",
      "Epoch 358/500\n",
      "6000/6000 [==============================] - 1s 142us/step - loss: 0.4168 - precision_14: 0.8084 - recall_14: 0.7898\n",
      "Epoch 359/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4172 - precision_14: 0.8084 - recall_14: 0.7898\n",
      "Epoch 360/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.4125 - precision_14: 0.8084 - recall_14: 0.7898\n",
      "Epoch 361/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.4045 - precision_14: 0.8085 - recall_14: 0.7898\n",
      "Epoch 362/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4044 - precision_14: 0.8085 - recall_14: 0.7899\n",
      "Epoch 363/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4044 - precision_14: 0.8085 - recall_14: 0.7899\n",
      "Epoch 364/500\n",
      "6000/6000 [==============================] - 1s 142us/step - loss: 0.3978 - precision_14: 0.8085 - recall_14: 0.7900\n",
      "Epoch 365/500\n",
      "6000/6000 [==============================] - 1s 142us/step - loss: 0.4056 - precision_14: 0.8085 - recall_14: 0.7900\n",
      "Epoch 366/500\n",
      "6000/6000 [==============================] - 1s 172us/step - loss: 0.4021 - precision_14: 0.8086 - recall_14: 0.7901\n",
      "Epoch 367/500\n",
      "6000/6000 [==============================] - 1s 156us/step - loss: 0.4048 - precision_14: 0.8086 - recall_14: 0.7901\n",
      "Epoch 368/500\n",
      "6000/6000 [==============================] - 1s 167us/step - loss: 0.4115 - precision_14: 0.8086 - recall_14: 0.7902\n",
      "Epoch 369/500\n",
      "6000/6000 [==============================] - 1s 155us/step - loss: 0.4110 - precision_14: 0.8086 - recall_14: 0.7902\n",
      "Epoch 370/500\n",
      "6000/6000 [==============================] - 1s 187us/step - loss: 0.3882 - precision_14: 0.8087 - recall_14: 0.7903\n",
      "Epoch 371/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.4130 - precision_14: 0.8087 - recall_14: 0.7904\n",
      "Epoch 372/500\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.4055 - precision_14: 0.8087 - recall_14: 0.7904\n",
      "Epoch 373/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.4118 - precision_14: 0.8087 - recall_14: 0.7904\n",
      "Epoch 374/500\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.4182 - precision_14: 0.8087 - recall_14: 0.7905\n",
      "Epoch 375/500\n",
      "6000/6000 [==============================] - 1s 151us/step - loss: 0.4030 - precision_14: 0.8088 - recall_14: 0.7905\n",
      "Epoch 376/500\n",
      "6000/6000 [==============================] - 1s 156us/step - loss: 0.4063 - precision_14: 0.8088 - recall_14: 0.7906\n",
      "Epoch 377/500\n",
      "6000/6000 [==============================] - 1s 150us/step - loss: 0.4117 - precision_14: 0.8088 - recall_14: 0.7906\n",
      "Epoch 378/500\n",
      "6000/6000 [==============================] - 1s 156us/step - loss: 0.4174 - precision_14: 0.8088 - recall_14: 0.7906\n",
      "Epoch 379/500\n",
      "6000/6000 [==============================] - 1s 172us/step - loss: 0.4038 - precision_14: 0.8088 - recall_14: 0.7907\n",
      "Epoch 380/500\n",
      "6000/6000 [==============================] - 1s 191us/step - loss: 0.4020 - precision_14: 0.8089 - recall_14: 0.7907\n",
      "Epoch 381/500\n",
      "6000/6000 [==============================] - 1s 205us/step - loss: 0.4055 - precision_14: 0.8089 - recall_14: 0.7908\n",
      "Epoch 382/500\n",
      "6000/6000 [==============================] - 1s 201us/step - loss: 0.4025 - precision_14: 0.8089 - recall_14: 0.7908\n",
      "Epoch 383/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.4122 - precision_14: 0.8089 - recall_14: 0.7908\n",
      "Epoch 384/500\n",
      "6000/6000 [==============================] - 1s 142us/step - loss: 0.4026 - precision_14: 0.8089 - recall_14: 0.7909\n",
      "Epoch 385/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4033 - precision_14: 0.8090 - recall_14: 0.7910\n",
      "Epoch 386/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.4055 - precision_14: 0.8090 - recall_14: 0.7910\n",
      "Epoch 387/500\n",
      "6000/6000 [==============================] - 1s 142us/step - loss: 0.3932 - precision_14: 0.8090 - recall_14: 0.7910\n",
      "Epoch 388/500\n",
      "6000/6000 [==============================] - 1s 152us/step - loss: 0.4028 - precision_14: 0.8091 - recall_14: 0.7911\n",
      "Epoch 389/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4034 - precision_14: 0.8091 - recall_14: 0.7912\n",
      "Epoch 390/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.3987 - precision_14: 0.8091 - recall_14: 0.7912\n",
      "Epoch 391/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.3999 - precision_14: 0.8091 - recall_14: 0.7912\n",
      "Epoch 392/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.4051 - precision_14: 0.8092 - recall_14: 0.7913\n",
      "Epoch 393/500\n",
      "6000/6000 [==============================] - 1s 157us/step - loss: 0.4153 - precision_14: 0.8092 - recall_14: 0.7913\n",
      "Epoch 394/500\n",
      "6000/6000 [==============================] - 1s 137us/step - loss: 0.4149 - precision_14: 0.8092 - recall_14: 0.7914\n",
      "Epoch 395/500\n",
      "6000/6000 [==============================] - 1s 140us/step - loss: 0.4139 - precision_14: 0.8092 - recall_14: 0.7914\n",
      "Epoch 396/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.4010 - precision_14: 0.8092 - recall_14: 0.7914\n",
      "Epoch 397/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4081 - precision_14: 0.8092 - recall_14: 0.7915\n",
      "Epoch 398/500\n",
      "6000/6000 [==============================] - 1s 151us/step - loss: 0.3995 - precision_14: 0.8092 - recall_14: 0.7915\n",
      "Epoch 399/500\n",
      "6000/6000 [==============================] - 1s 155us/step - loss: 0.4033 - precision_14: 0.8093 - recall_14: 0.7915\n",
      "Epoch 400/500\n",
      "6000/6000 [==============================] - 1s 170us/step - loss: 0.4010 - precision_14: 0.8093 - recall_14: 0.7916\n",
      "Epoch 401/500\n",
      "6000/6000 [==============================] - 1s 164us/step - loss: 0.4119 - precision_14: 0.8093 - recall_14: 0.7916\n",
      "Epoch 402/500\n",
      "6000/6000 [==============================] - 1s 163us/step - loss: 0.4014 - precision_14: 0.8093 - recall_14: 0.7917\n",
      "Epoch 403/500\n",
      "6000/6000 [==============================] - 1s 141us/step - loss: 0.4070 - precision_14: 0.8093 - recall_14: 0.7917\n",
      "Epoch 404/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.3999 - precision_14: 0.8093 - recall_14: 0.7917\n",
      "Epoch 405/500\n",
      "6000/6000 [==============================] - 1s 165us/step - loss: 0.4061 - precision_14: 0.8094 - recall_14: 0.7918\n",
      "Epoch 406/500\n",
      "6000/6000 [==============================] - 1s 169us/step - loss: 0.4034 - precision_14: 0.8094 - recall_14: 0.7918\n",
      "Epoch 407/500\n",
      "6000/6000 [==============================] - 1s 160us/step - loss: 0.4104 - precision_14: 0.8094 - recall_14: 0.7918\n",
      "Epoch 408/500\n",
      "6000/6000 [==============================] - 1s 162us/step - loss: 0.4095 - precision_14: 0.8094 - recall_14: 0.7919\n",
      "Epoch 409/500\n",
      "6000/6000 [==============================] - 1s 160us/step - loss: 0.4090 - precision_14: 0.8094 - recall_14: 0.7919\n",
      "Epoch 410/500\n",
      "6000/6000 [==============================] - 1s 181us/step - loss: 0.3951 - precision_14: 0.8095 - recall_14: 0.7920\n",
      "Epoch 411/500\n",
      "6000/6000 [==============================] - 1s 173us/step - loss: 0.4022 - precision_14: 0.8095 - recall_14: 0.7920\n",
      "Epoch 412/500\n",
      "6000/6000 [==============================] - 1s 172us/step - loss: 0.4044 - precision_14: 0.8095 - recall_14: 0.7921\n",
      "Epoch 413/500\n",
      "6000/6000 [==============================] - 1s 160us/step - loss: 0.4152 - precision_14: 0.8095 - recall_14: 0.7921\n",
      "Epoch 414/500\n",
      "6000/6000 [==============================] - 1s 181us/step - loss: 0.4044 - precision_14: 0.8095 - recall_14: 0.7921\n",
      "Epoch 415/500\n",
      "6000/6000 [==============================] - 1s 190us/step - loss: 0.4068 - precision_14: 0.8096 - recall_14: 0.7922\n",
      "Epoch 416/500\n",
      "6000/6000 [==============================] - 1s 174us/step - loss: 0.4129 - precision_14: 0.8096 - recall_14: 0.7922\n",
      "Epoch 417/500\n",
      "6000/6000 [==============================] - 1s 161us/step - loss: 0.4038 - precision_14: 0.8096 - recall_14: 0.7923\n",
      "Epoch 418/500\n",
      "6000/6000 [==============================] - 1s 161us/step - loss: 0.4095 - precision_14: 0.8096 - recall_14: 0.7923\n",
      "Epoch 419/500\n",
      "6000/6000 [==============================] - 1s 142us/step - loss: 0.4002 - precision_14: 0.8097 - recall_14: 0.7923\n",
      "Epoch 420/500\n",
      "6000/6000 [==============================] - 1s 190us/step - loss: 0.4171 - precision_14: 0.8097 - recall_14: 0.7924\n",
      "Epoch 421/500\n",
      "6000/6000 [==============================] - 1s 152us/step - loss: 0.4032 - precision_14: 0.8097 - recall_14: 0.7924\n",
      "Epoch 422/500\n",
      "6000/6000 [==============================] - 1s 153us/step - loss: 0.4035 - precision_14: 0.8097 - recall_14: 0.7924\n",
      "Epoch 423/500\n",
      "6000/6000 [==============================] - 1s 150us/step - loss: 0.3979 - precision_14: 0.8097 - recall_14: 0.7925\n",
      "Epoch 424/500\n",
      "6000/6000 [==============================] - 1s 152us/step - loss: 0.4119 - precision_14: 0.8098 - recall_14: 0.7925\n",
      "Epoch 425/500\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.4034 - precision_14: 0.8098 - recall_14: 0.7926\n",
      "Epoch 426/500\n",
      "6000/6000 [==============================] - 1s 155us/step - loss: 0.4060 - precision_14: 0.8098 - recall_14: 0.7926\n",
      "Epoch 427/500\n",
      "6000/6000 [==============================] - 1s 157us/step - loss: 0.3962 - precision_14: 0.8098 - recall_14: 0.7926\n",
      "Epoch 428/500\n",
      "6000/6000 [==============================] - 1s 155us/step - loss: 0.4035 - precision_14: 0.8098 - recall_14: 0.7927\n",
      "Epoch 429/500\n",
      "6000/6000 [==============================] - 1s 150us/step - loss: 0.3994 - precision_14: 0.8099 - recall_14: 0.7927\n",
      "Epoch 430/500\n",
      "6000/6000 [==============================] - 1s 141us/step - loss: 0.3983 - precision_14: 0.8099 - recall_14: 0.7928\n",
      "Epoch 431/500\n",
      "6000/6000 [==============================] - 1s 150us/step - loss: 0.4004 - precision_14: 0.8099 - recall_14: 0.7928\n",
      "Epoch 432/500\n",
      "6000/6000 [==============================] - 1s 159us/step - loss: 0.4074 - precision_14: 0.8099 - recall_14: 0.7929\n",
      "Epoch 433/500\n",
      "6000/6000 [==============================] - 1s 158us/step - loss: 0.4057 - precision_14: 0.8099 - recall_14: 0.7929\n",
      "Epoch 434/500\n",
      "6000/6000 [==============================] - 1s 159us/step - loss: 0.4081 - precision_14: 0.8100 - recall_14: 0.7929\n",
      "Epoch 435/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 1s 152us/step - loss: 0.4078 - precision_14: 0.8100 - recall_14: 0.7930\n",
      "Epoch 436/500\n",
      "6000/6000 [==============================] - 1s 138us/step - loss: 0.3988 - precision_14: 0.8100 - recall_14: 0.7930\n",
      "Epoch 437/500\n",
      "6000/6000 [==============================] - 1s 162us/step - loss: 0.3995 - precision_14: 0.8100 - recall_14: 0.7930\n",
      "Epoch 438/500\n",
      "6000/6000 [==============================] - 1s 170us/step - loss: 0.4076 - precision_14: 0.8100 - recall_14: 0.7931\n",
      "Epoch 439/500\n",
      "6000/6000 [==============================] - 1s 174us/step - loss: 0.4100 - precision_14: 0.8100 - recall_14: 0.7931\n",
      "Epoch 440/500\n",
      "6000/6000 [==============================] - 1s 155us/step - loss: 0.4115 - precision_14: 0.8101 - recall_14: 0.7931\n",
      "Epoch 441/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.3987 - precision_14: 0.8101 - recall_14: 0.7932\n",
      "Epoch 442/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.4093 - precision_14: 0.8101 - recall_14: 0.7932\n",
      "Epoch 443/500\n",
      "6000/6000 [==============================] - 1s 152us/step - loss: 0.4115 - precision_14: 0.8101 - recall_14: 0.7932\n",
      "Epoch 444/500\n",
      "6000/6000 [==============================] - 1s 168us/step - loss: 0.4052 - precision_14: 0.8101 - recall_14: 0.7933\n",
      "Epoch 445/500\n",
      "6000/6000 [==============================] - 1s 164us/step - loss: 0.4067 - precision_14: 0.8101 - recall_14: 0.7933\n",
      "Epoch 446/500\n",
      "6000/6000 [==============================] - 1s 169us/step - loss: 0.4002 - precision_14: 0.8101 - recall_14: 0.7933\n",
      "Epoch 447/500\n",
      "6000/6000 [==============================] - 1s 149us/step - loss: 0.4104 - precision_14: 0.8102 - recall_14: 0.7934\n",
      "Epoch 448/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4086 - precision_14: 0.8102 - recall_14: 0.7934\n",
      "Epoch 449/500\n",
      "6000/6000 [==============================] - 1s 156us/step - loss: 0.3901 - precision_14: 0.8102 - recall_14: 0.7934\n",
      "Epoch 450/500\n",
      "6000/6000 [==============================] - 1s 157us/step - loss: 0.3935 - precision_14: 0.8102 - recall_14: 0.7935\n",
      "Epoch 451/500\n",
      "6000/6000 [==============================] - 1s 155us/step - loss: 0.3942 - precision_14: 0.8103 - recall_14: 0.7936\n",
      "Epoch 452/500\n",
      "6000/6000 [==============================] - 1s 155us/step - loss: 0.4062 - precision_14: 0.8103 - recall_14: 0.7936\n",
      "Epoch 453/500\n",
      "6000/6000 [==============================] - 1s 155us/step - loss: 0.4034 - precision_14: 0.8103 - recall_14: 0.7936\n",
      "Epoch 454/500\n",
      "6000/6000 [==============================] - 1s 160us/step - loss: 0.3982 - precision_14: 0.8104 - recall_14: 0.7937\n",
      "Epoch 455/500\n",
      "6000/6000 [==============================] - 1s 155us/step - loss: 0.3930 - precision_14: 0.8104 - recall_14: 0.7937\n",
      "Epoch 456/500\n",
      "6000/6000 [==============================] - 1s 156us/step - loss: 0.3982 - precision_14: 0.8104 - recall_14: 0.7938\n",
      "Epoch 457/500\n",
      "6000/6000 [==============================] - 1s 158us/step - loss: 0.4098 - precision_14: 0.8104 - recall_14: 0.7938\n",
      "Epoch 458/500\n",
      "6000/6000 [==============================] - 1s 151us/step - loss: 0.4054 - precision_14: 0.8104 - recall_14: 0.7938\n",
      "Epoch 459/500\n",
      "6000/6000 [==============================] - 1s 192us/step - loss: 0.4116 - precision_14: 0.8104 - recall_14: 0.7938\n",
      "Epoch 460/500\n",
      "6000/6000 [==============================] - 1s 179us/step - loss: 0.4025 - precision_14: 0.8104 - recall_14: 0.7939\n",
      "Epoch 461/500\n",
      "6000/6000 [==============================] - 1s 184us/step - loss: 0.4110 - precision_14: 0.8105 - recall_14: 0.7939\n",
      "Epoch 462/500\n",
      "6000/6000 [==============================] - 1s 171us/step - loss: 0.4079 - precision_14: 0.8105 - recall_14: 0.7939\n",
      "Epoch 463/500\n",
      "6000/6000 [==============================] - 1s 212us/step - loss: 0.4024 - precision_14: 0.8105 - recall_14: 0.7940\n",
      "Epoch 464/500\n",
      "6000/6000 [==============================] - 1s 192us/step - loss: 0.4083 - precision_14: 0.8105 - recall_14: 0.7940\n",
      "Epoch 465/500\n",
      "6000/6000 [==============================] - 1s 164us/step - loss: 0.3956 - precision_14: 0.8105 - recall_14: 0.7940\n",
      "Epoch 466/500\n",
      "6000/6000 [==============================] - 1s 221us/step - loss: 0.4181 - precision_14: 0.8105 - recall_14: 0.7941\n",
      "Epoch 467/500\n",
      "6000/6000 [==============================] - 1s 202us/step - loss: 0.3956 - precision_14: 0.8106 - recall_14: 0.7941\n",
      "Epoch 468/500\n",
      "6000/6000 [==============================] - 1s 195us/step - loss: 0.4162 - precision_14: 0.8106 - recall_14: 0.7941\n",
      "Epoch 469/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.4078 - precision_14: 0.8106 - recall_14: 0.7942\n",
      "Epoch 470/500\n",
      "6000/6000 [==============================] - 1s 162us/step - loss: 0.4076 - precision_14: 0.8106 - recall_14: 0.7942\n",
      "Epoch 471/500\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.3985 - precision_14: 0.8106 - recall_14: 0.7942\n",
      "Epoch 472/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.3941 - precision_14: 0.8106 - recall_14: 0.7943\n",
      "Epoch 473/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.4030 - precision_14: 0.8107 - recall_14: 0.7943\n",
      "Epoch 474/500\n",
      "6000/6000 [==============================] - 1s 153us/step - loss: 0.4000 - precision_14: 0.8107 - recall_14: 0.7944\n",
      "Epoch 475/500\n",
      "6000/6000 [==============================] - 1s 150us/step - loss: 0.4022 - precision_14: 0.8107 - recall_14: 0.7944\n",
      "Epoch 476/500\n",
      "6000/6000 [==============================] - 1s 152us/step - loss: 0.3954 - precision_14: 0.8108 - recall_14: 0.7944\n",
      "Epoch 477/500\n",
      "6000/6000 [==============================] - 1s 153us/step - loss: 0.4075 - precision_14: 0.8108 - recall_14: 0.7945\n",
      "Epoch 478/500\n",
      "6000/6000 [==============================] - 1s 179us/step - loss: 0.4003 - precision_14: 0.8108 - recall_14: 0.7945\n",
      "Epoch 479/500\n",
      "6000/6000 [==============================] - 1s 160us/step - loss: 0.3995 - precision_14: 0.8108 - recall_14: 0.7945\n",
      "Epoch 480/500\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.4180 - precision_14: 0.8108 - recall_14: 0.7946\n",
      "Epoch 481/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.3946 - precision_14: 0.8108 - recall_14: 0.7946\n",
      "Epoch 482/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.4010 - precision_14: 0.8108 - recall_14: 0.7946\n",
      "Epoch 483/500\n",
      "6000/6000 [==============================] - 1s 142us/step - loss: 0.4045 - precision_14: 0.8109 - recall_14: 0.7947\n",
      "Epoch 484/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.4166 - precision_14: 0.8109 - recall_14: 0.7947\n",
      "Epoch 485/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.3898 - precision_14: 0.8109 - recall_14: 0.7947\n",
      "Epoch 486/500\n",
      "6000/6000 [==============================] - 1s 143us/step - loss: 0.4041 - precision_14: 0.8109 - recall_14: 0.7948\n",
      "Epoch 487/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.4161 - precision_14: 0.8109 - recall_14: 0.7948\n",
      "Epoch 488/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.4083 - precision_14: 0.8109 - recall_14: 0.7948\n",
      "Epoch 489/500\n",
      "6000/6000 [==============================] - 1s 149us/step - loss: 0.3953 - precision_14: 0.8110 - recall_14: 0.7948\n",
      "Epoch 490/500\n",
      "6000/6000 [==============================] - 1s 150us/step - loss: 0.3984 - precision_14: 0.8110 - recall_14: 0.7949\n",
      "Epoch 491/500\n",
      "6000/6000 [==============================] - 1s 154us/step - loss: 0.4058 - precision_14: 0.8110 - recall_14: 0.7949\n",
      "Epoch 492/500\n",
      "6000/6000 [==============================] - 1s 146us/step - loss: 0.3987 - precision_14: 0.8110 - recall_14: 0.7949\n",
      "Epoch 493/500\n",
      "6000/6000 [==============================] - 1s 141us/step - loss: 0.3901 - precision_14: 0.8110 - recall_14: 0.7950\n",
      "Epoch 494/500\n",
      "6000/6000 [==============================] - 1s 142us/step - loss: 0.4023 - precision_14: 0.8110 - recall_14: 0.7950\n",
      "Epoch 495/500\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.4036 - precision_14: 0.8111 - recall_14: 0.7950\n",
      "Epoch 496/500\n",
      "6000/6000 [==============================] - 1s 151us/step - loss: 0.4040 - precision_14: 0.8111 - recall_14: 0.7951\n",
      "Epoch 497/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 1s 142us/step - loss: 0.4128 - precision_14: 0.8111 - recall_14: 0.7951\n",
      "Epoch 498/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.4028 - precision_14: 0.8111 - recall_14: 0.7951\n",
      "Epoch 499/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.3950 - precision_14: 0.8111 - recall_14: 0.7951\n",
      "Epoch 500/500\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.3999 - precision_14: 0.8111 - recall_14: 0.7952\n",
      "TRAIN\n",
      "Evaluation metrics: \n",
      "6000/6000 [==============================] - 0s 36us/step\n",
      "[0.27588961803913115, 0.8112308979034424, 0.7952876091003418]\n",
      "6000/6000 [==============================] - 0s 14us/step\n",
      "Confusion matrix: \n",
      "        All()  Both()  Most()  No()  Some()  The()\n",
      "All()    1000       0       0     0       0      0\n",
      "Both()      0     922       0     0       0     78\n",
      "Most()      5       0     799     0     194      2\n",
      "No()        0       0       0  1000       0      0\n",
      "Some()     10       0      73     1     916      0\n",
      "The()       0     283       0     0       0    717\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       All()     0.9852    1.0000    0.9926      1000\n",
      "      Both()     0.7651    0.9220    0.8363      1000\n",
      "      Most()     0.9163    0.7990    0.8536      1000\n",
      "        No()     0.9990    1.0000    0.9995      1000\n",
      "      Some()     0.8252    0.9160    0.8682      1000\n",
      "       The()     0.8996    0.7170    0.7980      1000\n",
      "\n",
      "    accuracy                         0.8923      6000\n",
      "   macro avg     0.8984    0.8923    0.8914      6000\n",
      "weighted avg     0.8984    0.8923    0.8914      6000\n",
      "\n",
      "TEST\n",
      "Evaluation metrics: \n",
      "6000/6000 [==============================] - 0s 30us/step\n",
      "[0.6830338775316874, 0.8112068176269531, 0.7952857613563538]\n",
      "6000/6000 [==============================] - 0s 11us/step\n",
      "Confusion matrix: \n",
      "        All()  Both()  Most()  No()  Some()  The()\n",
      "All()     979      13       1     0       0      7\n",
      "Both()      0     610       0     0       0    390\n",
      "Most()     65      20     489     0     410     16\n",
      "No()        0      10       1   983       0      6\n",
      "Some()     60       0     221    30     689      0\n",
      "The()       0     541       0     0       0    459\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       All()     0.8868    0.9790    0.9306      1000\n",
      "      Both()     0.5109    0.6100    0.5561      1000\n",
      "      Most()     0.6868    0.4890    0.5713      1000\n",
      "        No()     0.9704    0.9830    0.9767      1000\n",
      "      Some()     0.6269    0.6890    0.6565      1000\n",
      "       The()     0.5228    0.4590    0.4888      1000\n",
      "\n",
      "    accuracy                         0.7015      6000\n",
      "   macro avg     0.7008    0.7015    0.6967      6000\n",
      "weighted avg     0.7008    0.7015    0.6967      6000\n",
      "\n",
      "1000/1000 [==============================] - 0s 17us/step\n",
      "Quantifier counts:  [  0   0 545   0 455]\n",
      "Support:  1000\n",
      "Accuracy:  0.455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.CNNClassifier at 0x7fae19954520>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = CNNClassifier(natural_quantifiers)\n",
    "# classifier = DNNClassifier(natural_quantifiers)\n",
    "# classifier = DDNNClassifier(natural_quantifiers)\n",
    "classifier.plot()\n",
    "classifier.learn(epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 500, 4) (None, 500, 2)\n",
      "(None, 1000) (None, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.1076507 ,  0.13008717, -0.01818368, -0.22356793, -0.00356855,\n",
       "         -0.00904826],\n",
       "        [-0.0006467 ,  0.0793877 ,  0.10010331, -0.095723  , -0.1381944 ,\n",
       "          0.02341199],\n",
       "        [ 0.09779829,  0.02340156, -0.00931393, -0.06722328,  0.0653357 ,\n",
       "         -0.04348795],\n",
       "        ...,\n",
       "        [ 0.01721711,  0.1114671 , -0.07544132,  0.05401943, -0.07675583,\n",
       "          0.1960058 ],\n",
       "        [ 0.15859719, -0.02447802, -0.08564785, -0.07498336, -0.0054255 ,\n",
       "         -0.02525638],\n",
       "        [-0.00150776,  0.12157026, -0.02007886,  0.05680544, -0.05764136,\n",
       "          0.01590555]], dtype=float32),\n",
       " array([ 0.26824734, -0.29823148,  1.1078876 , -0.544239  , -0.3411305 ,\n",
       "        -0.3680084 ], dtype=float32)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(natural_classifier._model.get_layer(name=\"conv_1\").input_shape,\n",
    "#       natural_classifier._model.get_layer(name=\"conv_1\").output_shape)\n",
    "# natural_classifier._model.get_layer(name=\"conv_1\").get_weights()\n",
    "# print(natural_classifier._model.get_layer(name=\"softmax_1\").input_shape,\n",
    "#       natural_classifier._model.get_layer(name=\"softmax_1\").output_shape)\n",
    "# natural_classifier._model.get_layer(name=\"softmax_1\").get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x230.4 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(6, 3.2))\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title('colorMap')\n",
    "plt.imshow(natural_classifier._model.get_layer(name=\"softmax_1\").get_weights()[0])\n",
    "ax.set_aspect(1 / 100)\n",
    "\n",
    "cax = fig.add_axes([0.12, 0.1, 0.78, 0.8])\n",
    "cax.get_xaxis().set_visible(False)\n",
    "cax.get_yaxis().set_visible(False)\n",
    "cax.patch.set_alpha(0)\n",
    "cax.set_frame_on(False)\n",
    "plt.colorbar(orientation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNNClassifier model classifies ['MinMax(mini=12,maxi=15)' 'MinMax(mini=17,maxi=20)'\n",
      " 'MinMax(mini=2,maxi=5)' 'MinMax(mini=24,maxi=30)'\n",
      " 'MinMax(mini=37,maxi=50)' 'MinMax(mini=8,maxi=10)']\n",
      "Epoch 1/50\n",
      "600/600 [==============================] - 0s 404us/step - loss: 3.0381 - precision_38: 0.1388 - recall_38: 0.0970\n",
      "Epoch 2/50\n",
      "600/600 [==============================] - 0s 261us/step - loss: 1.8824 - precision_38: 0.1562 - recall_38: 0.0610\n",
      "Epoch 3/50\n",
      "600/600 [==============================] - 0s 259us/step - loss: 1.7974 - precision_38: 0.1565 - recall_38: 0.0364\n",
      "Epoch 4/50\n",
      "600/600 [==============================] - 0s 258us/step - loss: 1.7813 - precision_38: 0.1570 - recall_38: 0.0259\n",
      "Epoch 5/50\n",
      "600/600 [==============================] - 0s 271us/step - loss: 1.7926 - precision_38: 0.1587 - recall_38: 0.0204\n",
      "Epoch 6/50\n",
      "600/600 [==============================] - 0s 264us/step - loss: 1.7859 - precision_38: 0.1585 - recall_38: 0.0167\n",
      "Epoch 7/50\n",
      "600/600 [==============================] - 0s 250us/step - loss: 1.7879 - precision_38: 0.1585 - recall_38: 0.0141\n",
      "Epoch 8/50\n",
      "600/600 [==============================] - 0s 269us/step - loss: 1.7924 - precision_38: 0.1573 - recall_38: 0.0122\n",
      "Epoch 9/50\n",
      "600/600 [==============================] - 0s 262us/step - loss: 1.7847 - precision_38: 0.1567 - recall_38: 0.0108\n",
      "Epoch 10/50\n",
      "600/600 [==============================] - 0s 258us/step - loss: 1.7920 - precision_38: 0.1567 - recall_38: 0.0096\n",
      "Epoch 11/50\n",
      "600/600 [==============================] - 0s 276us/step - loss: 1.7817 - precision_38: 0.1567 - recall_38: 0.0087\n",
      "Epoch 12/50\n",
      "600/600 [==============================] - 0s 279us/step - loss: 1.7909 - precision_38: 0.1568 - recall_38: 0.0080\n",
      "Epoch 13/50\n",
      "600/600 [==============================] - 0s 285us/step - loss: 1.7815 - precision_38: 0.1577 - recall_38: 0.0075\n",
      "Epoch 14/50\n",
      "600/600 [==============================] - 0s 278us/step - loss: 1.7954 - precision_38: 0.1577 - recall_38: 0.0069\n",
      "Epoch 15/50\n",
      "600/600 [==============================] - 0s 269us/step - loss: 1.7683 - precision_38: 0.1577 - recall_38: 0.0064\n",
      "Epoch 16/50\n",
      "600/600 [==============================] - 0s 279us/step - loss: 1.7724 - precision_38: 0.1577 - recall_38: 0.0060\n",
      "Epoch 17/50\n",
      "600/600 [==============================] - 0s 273us/step - loss: 1.7794 - precision_38: 0.1577 - recall_38: 0.0057\n",
      "Epoch 18/50\n",
      "600/600 [==============================] - 0s 265us/step - loss: 1.7737 - precision_38: 0.1577 - recall_38: 0.0053\n",
      "Epoch 19/50\n",
      "600/600 [==============================] - 0s 256us/step - loss: 1.7809 - precision_38: 0.1577 - recall_38: 0.0050\n",
      "Epoch 20/50\n",
      "600/600 [==============================] - 0s 269us/step - loss: 1.7759 - precision_38: 0.1577 - recall_38: 0.0048\n",
      "Epoch 21/50\n",
      "600/600 [==============================] - 0s 279us/step - loss: 1.7667 - precision_38: 0.1581 - recall_38: 0.0046\n",
      "Epoch 22/50\n",
      "600/600 [==============================] - 0s 288us/step - loss: 1.7741 - precision_38: 0.1601 - recall_38: 0.0044\n",
      "Epoch 23/50\n",
      "600/600 [==============================] - 0s 275us/step - loss: 1.7473 - precision_38: 0.1602 - recall_38: 0.0042\n",
      "Epoch 24/50\n",
      "600/600 [==============================] - 0s 345us/step - loss: 1.7698 - precision_38: 0.1645 - recall_38: 0.0042\n",
      "Epoch 25/50\n",
      "600/600 [==============================] - 0s 310us/step - loss: 1.7405 - precision_38: 0.1648 - recall_38: 0.0040\n",
      "Epoch 26/50\n",
      "600/600 [==============================] - 0s 300us/step - loss: 1.7621 - precision_38: 0.1660 - recall_38: 0.0039\n",
      "Epoch 27/50\n",
      "600/600 [==============================] - 0s 349us/step - loss: 1.7841 - precision_38: 0.1688 - recall_38: 0.0039\n",
      "Epoch 28/50\n",
      "600/600 [==============================] - 0s 301us/step - loss: 1.7754 - precision_38: 0.1685 - recall_38: 0.0038\n",
      "Epoch 29/50\n",
      "600/600 [==============================] - 0s 314us/step - loss: 1.7850 - precision_38: 0.1685 - recall_38: 0.0036\n",
      "Epoch 30/50\n",
      "600/600 [==============================] - 0s 235us/step - loss: 1.7928 - precision_38: 0.1685 - recall_38: 0.0035\n",
      "Epoch 31/50\n",
      "600/600 [==============================] - 0s 245us/step - loss: 1.7924 - precision_38: 0.1685 - recall_38: 0.0034\n",
      "Epoch 32/50\n",
      "600/600 [==============================] - 0s 252us/step - loss: 1.7926 - precision_38: 0.1685 - recall_38: 0.0033\n",
      "Epoch 33/50\n",
      "600/600 [==============================] - 0s 260us/step - loss: 1.7920 - precision_38: 0.1685 - recall_38: 0.0032\n",
      "Epoch 34/50\n",
      "600/600 [==============================] - 0s 253us/step - loss: 1.7936 - precision_38: 0.1685 - recall_38: 0.0031\n",
      "Epoch 35/50\n",
      "600/600 [==============================] - 0s 256us/step - loss: 1.7922 - precision_38: 0.1685 - recall_38: 0.0030\n",
      "Epoch 36/50\n",
      "600/600 [==============================] - 0s 256us/step - loss: 1.7864 - precision_38: 0.1685 - recall_38: 0.0029\n",
      "Epoch 37/50\n",
      "600/600 [==============================] - 0s 261us/step - loss: 1.7732 - precision_38: 0.1685 - recall_38: 0.0028\n",
      "Epoch 38/50\n",
      "600/600 [==============================] - 0s 259us/step - loss: 1.7922 - precision_38: 0.1685 - recall_38: 0.0028\n",
      "Epoch 39/50\n",
      "600/600 [==============================] - 0s 319us/step - loss: 1.7924 - precision_38: 0.1685 - recall_38: 0.0027\n",
      "Epoch 40/50\n",
      "600/600 [==============================] - 0s 303us/step - loss: 1.7919 - precision_38: 0.1685 - recall_38: 0.0026\n",
      "Epoch 41/50\n",
      "600/600 [==============================] - 0s 268us/step - loss: 1.7923 - precision_38: 0.1685 - recall_38: 0.0026\n",
      "Epoch 42/50\n",
      "600/600 [==============================] - 0s 252us/step - loss: 1.7891 - precision_38: 0.1685 - recall_38: 0.0025\n",
      "Epoch 43/50\n",
      "600/600 [==============================] - 0s 247us/step - loss: 1.7892 - precision_38: 0.1685 - recall_38: 0.0024\n",
      "Epoch 44/50\n",
      "600/600 [==============================] - 0s 254us/step - loss: 1.7930 - precision_38: 0.1685 - recall_38: 0.0024\n",
      "Epoch 45/50\n",
      "600/600 [==============================] - 0s 261us/step - loss: 1.7922 - precision_38: 0.1685 - recall_38: 0.0023\n",
      "Epoch 46/50\n",
      "600/600 [==============================] - 0s 258us/step - loss: 1.7921 - precision_38: 0.1685 - recall_38: 0.0023\n",
      "Epoch 47/50\n",
      "600/600 [==============================] - 0s 258us/step - loss: 1.7922 - precision_38: 0.1685 - recall_38: 0.0022\n",
      "Epoch 48/50\n",
      "600/600 [==============================] - 0s 256us/step - loss: 1.7922 - precision_38: 0.1685 - recall_38: 0.0022\n",
      "Epoch 49/50\n",
      "600/600 [==============================] - 0s 262us/step - loss: 1.7921 - precision_38: 0.1685 - recall_38: 0.0021\n",
      "Epoch 50/50\n",
      "600/600 [==============================] - 0s 257us/step - loss: 1.7923 - precision_38: 0.1685 - recall_38: 0.0021\n",
      "Evaluation metrics: \n",
      "6000/6000 [==============================] - 0s 31us/step\n",
      "[1.7918116060892741, 0.1684781014919281, 0.0018826446030288935]\n",
      "Confusion matrix: \n",
      "[[  3  12   0   1 974  10]\n",
      " [  2  20   3   3 961  11]\n",
      " [  1  10   1   0 982   6]\n",
      " [  4  26   2   1 953  14]\n",
      " [ 10  41   2   6 912  29]\n",
      " [  4  14   3   2 971   6]]\n",
      "Classification report: \n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "MinMax(mini=12,maxi=15)     0.1250    0.0030    0.0059      1000\n",
      "MinMax(mini=17,maxi=20)     0.1626    0.0200    0.0356      1000\n",
      "  MinMax(mini=2,maxi=5)     0.0909    0.0010    0.0020      1000\n",
      "MinMax(mini=24,maxi=30)     0.0769    0.0010    0.0020      1000\n",
      "MinMax(mini=37,maxi=50)     0.1585    0.9120    0.2701      1000\n",
      " MinMax(mini=8,maxi=10)     0.0789    0.0060    0.0112      1000\n",
      "\n",
      "               accuracy                         0.1572      6000\n",
      "              macro avg     0.1155    0.1572    0.0544      6000\n",
      "           weighted avg     0.1155    0.1572    0.0544      6000\n",
      "\n",
      "Quantifier counts:  [ 67 195  49  70 469 150]\n",
      "NO SUPPORT\n"
     ]
    }
   ],
   "source": [
    "# unnatural_classifier = teach(CNNClassifier(unnatural_quantifiers), epochs=50, max_len=10)\n",
    "unnatural_classifier = DNNClassifier(unnatural_quantifiers).teach, epochs=50, max_len=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
