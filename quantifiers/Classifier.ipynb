{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier  approach\n",
    "---\n",
    "This approach assumes that quantifiers are learned as a group and that essentially each q quantifier example is a negative example for all other quantifiers q'.\n",
    "\n",
    "The classifier is in effect a solver for which q makes the sentence \"Q as are bs\" most likely given an input scene s.\n",
    "\n",
    "This enables us to use not only the quantifier quantify evaluation methods but the classifier in order to generate a teacher-student scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### my class imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from quants.quantifiers import *\n",
    "from quants.classifiers import SingleLabelClassifier, MultiLabelClassifier, CNNClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras and TF imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.4.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, Embedding, Dense, Conv1D, Input, Bidirectional, RepeatVector, Dropout, LeakyReLU, Flatten, Concatenate\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.8.6 (default, Jan 27 2021, 15:42:20) \n",
      "[GCC 10.2.0]\n",
      "Version info.\n",
      "sys.version_info(major=3, minor=8, micro=6, releaselevel='final', serial=0)\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Python version\")\n",
    "print (sys.version)\n",
    "print(\"Version info.\")\n",
    "print (sys.version_info)\n",
    "\n",
    "print(tf.config.list_physical_devices(device_type='CPU'))\n",
    "# print(\"Keras backend: \", tf.compat.v1.keras.backend.backend())\n",
    "# print(tf.config.list_logical_devices())\n",
    "\n",
    "# gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.3)\n",
    "# sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "# K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDNNSoftmaxClassifier(SingleLabelClassifier):\n",
    "    \"\"\" deep softmax dense classifier model builder method \"\"\"\n",
    "    \n",
    "    def build(self):\n",
    "        model= Sequential()\n",
    "        model.add(Dense(Quantifier.scene_len, activation=\"relu\", name=\"input\"))\n",
    "        model.add(Dropout(0.25, name=\"dropout_1\"))\n",
    "        model.add(Dense(100, activation=\"relu\", name=\"dense_2\"))\n",
    "        model.add(Dropout(0.25, name=\"dropout_2\"))\n",
    "        model.add(Dense(50, activation=\"relu\", name=\"dense_3\"))\n",
    "        model.add(Dropout(0.25, name=\"dropout_3\"))\n",
    "        model.add(Dense(len(self._quantifiers), activation='softmax', name=\"softmax_1\"))\n",
    "        # Compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Precision(),\n",
    "                                                                                  tf.keras.metrics.Recall()])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNSoftmaxClassifier(SingleLabelClassifier):\n",
    "    \"\"\" dense classifier model builder method \"\"\"\n",
    "    \n",
    "    def build(self):\n",
    "        model= Sequential()\n",
    "        model.add(Dense(Quantifier.scene_len, activation=\"relu\", name=\"input\"))\n",
    "        model.add(Dropout(0.5, name=\"dropout_1\"))\n",
    "        model.add(Dense(len(self._quantifiers), activation='softmax', name=\"softmax_1\"))\n",
    "        # Compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Precision(),\n",
    "                                                                                  tf.keras.metrics.Recall()])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClassifier(CNNClassifier, SingleLabelClassifier):\n",
    "    \"\"\"\n",
    "    classifier class\n",
    "    classifies list of quantifiers\n",
    "    \"\"\"\n",
    "\n",
    "    def build(self):\n",
    "        num_kernels = len(self._kernels)\n",
    "        const_initializer_0 = tf.keras.initializers.Constant(0.)\n",
    "        const_initializer_1 = tf.keras.initializers.Constant(1.)\n",
    "        # input layer\n",
    "        scene = Input(name='input', shape=(Quantifier.scene_len, len(symbols)))\n",
    "        # conv\n",
    "        conv = Conv1D(filters=num_kernels, kernel_size=1,\n",
    "                      kernel_initializer=const_initializer_1,\n",
    "                      trainable=False,\n",
    "                      use_bias=False,\n",
    "                      name='conv')(scene)\n",
    "        # split to handle each kernel seperately\n",
    "        splitters = tf.split(conv, num_kernels, axis=2, name='split')\n",
    "        # flatten the result (reshapes)\n",
    "        flats = [Flatten(name='flat_{i}'.format(i=i))(splitters[i])\n",
    "                 for i in range(num_kernels)]\n",
    "        # dropouts after convolutions\n",
    "        dropouts = [Dropout(rate=0.01, name='dropout_{i}'.format(i=i))(flats[i])\n",
    "                    for i in range(num_kernels)]\n",
    "        # single neuron summarizers\n",
    "        denses = [Dense(1,\n",
    "                        kernel_initializer=const_initializer_1,\n",
    "                        use_bias=False,\n",
    "                        trainable=False,\n",
    "                        activation='linear',\n",
    "                        name='dense_{i}'.format(i=i))(dropouts[i])\n",
    "                  for i in range(num_kernels)]\n",
    "        # merge feature extractors\n",
    "        merge = tf.concat(denses, axis=1, name='concatenate')\n",
    "#         dense = Dense(len(self._quantifier_names),\n",
    "#                         kernel_initializer=const_initializer_1,\n",
    "#                         use_bias=True,\n",
    "#                         trainable=True,\n",
    "#                         activation='relu', name=\"dense\")(merge)\n",
    "        # softmax layer\n",
    "        softmax = Dense(len(self._quantifier_names),\n",
    "                        kernel_initializer=const_initializer_0,\n",
    "                        use_bias=True,\n",
    "                        trainable=True,\n",
    "                        activation='softmax', name=\"softmax\")(merge)\n",
    "        # inputs outputs\n",
    "        model = Model(inputs=scene, outputs=softmax)\n",
    "        # set weights\n",
    "        conv = model.get_layer('conv')\n",
    "        conv.set_weights([np.array([self._kernels]).transpose().reshape(1, len(symbols), num_kernels)])\n",
    "        print(conv.get_weights())\n",
    "        # compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "                      metrics=[\n",
    "                          tf.keras.metrics.Precision()\n",
    "                          , tf.keras.metrics.Recall()\n",
    "                      ])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifier sets for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_quantifiers = [The(), Both(), No(), All(), Some(), Most()]\n",
    "# natural_quantifiers = [All(), Most(), Some()]\n",
    "most_quantifiers = [Most(), Not(Most())]\n",
    "every_quantifiers = [All2()]\n",
    "quantifiers = [Between(2, 50), All()]\n",
    "monotonicity_quantifiers = [Most(), Between(20, 50)]\n",
    "unnatural_quantifiers = [Between(20, 50), Between(8, 40), Between(12, 35)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]]], dtype=float32)]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 500, 4)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv (Conv1D)                   (None, 500, 2)       8           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.split (TFOpLambda)           [(None, 500, 1), (No 0           conv[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flat_0 (Flatten)                (None, 500)          0           tf.split[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flat_1 (Flatten)                (None, 500)          0           tf.split[0][1]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_0 (Dropout)             (None, 500)          0           flat_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 500)          0           flat_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 1)            500         dropout_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            500         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat (TFOpLambda)          (None, 2)            0           dense_0[0][0]                    \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Dense)                 (None, 2)            6           tf.concat[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,014\n",
      "Trainable params: 6\n",
      "Non-trainable params: 1,008\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "MyClassifier model classifies ['All2()', 'Other']\n"
     ]
    }
   ],
   "source": [
    "classifier = MyClassifier(kernels=[[1, 0, 0, 0],  [0, 1, 0, 0]] , # [1, -1, 0, 0],], \n",
    "                          quantifiers=[All2()], other=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Epoch 1/25\n",
      "7168/7168 [==============================] - 8s 1ms/step - loss: 0.2719 - precision: 0.9356 - recall: 0.9345\n",
      "Epoch 2/25\n",
      "7168/7168 [==============================] - 8s 1ms/step - loss: 0.1733 - precision: 0.9439 - recall: 0.9439\n",
      "Epoch 3/25\n",
      "7168/7168 [==============================] - 8s 1ms/step - loss: 0.1534 - precision: 0.9573 - recall: 0.9573\n",
      "Epoch 4/25\n",
      "7168/7168 [==============================] - 7s 999us/step - loss: 0.1508 - precision: 0.9562 - recall: 0.9562\n",
      "Epoch 5/25\n",
      "7168/7168 [==============================] - 7s 1ms/step - loss: 0.1333 - precision: 0.9623 - recall: 0.9623\n",
      "Epoch 6/25\n",
      "7168/7168 [==============================] - 7s 1ms/step - loss: 0.1492 - precision: 0.9584 - recall: 0.9584\n",
      "Epoch 7/25\n",
      "7168/7168 [==============================] - 8s 1ms/step - loss: 0.1202 - precision: 0.9634 - recall: 0.9634\n",
      "Epoch 8/25\n",
      "7168/7168 [==============================] - 8s 1ms/step - loss: 0.1169 - precision: 0.9669 - recall: 0.9669\n",
      "Epoch 9/25\n",
      "7168/7168 [==============================] - 7s 1ms/step - loss: 0.1381 - precision: 0.9600 - recall: 0.9600\n",
      "Epoch 10/25\n",
      "7168/7168 [==============================] - 8s 1ms/step - loss: 0.1156 - precision: 0.9667 - recall: 0.9667\n",
      "Epoch 11/25\n",
      "7168/7168 [==============================] - 7s 1ms/step - loss: 0.1064 - precision: 0.9685 - recall: 0.9685\n",
      "Epoch 12/25\n",
      "7168/7168 [==============================] - 7s 1ms/step - loss: 0.1038 - precision: 0.9713 - recall: 0.9713\n",
      "Epoch 13/25\n",
      "7168/7168 [==============================] - 7s 1ms/step - loss: 0.1067 - precision: 0.9645 - recall: 0.9645\n",
      "Epoch 14/25\n",
      "7168/7168 [==============================] - 7s 1ms/step - loss: 0.0967 - precision: 0.9691 - recall: 0.9691\n",
      "Epoch 15/25\n",
      "7168/7168 [==============================] - 8s 1ms/step - loss: 0.1002 - precision: 0.9718 - recall: 0.9718\n",
      "Epoch 16/25\n",
      "7168/7168 [==============================] - 7s 1ms/step - loss: 0.0945 - precision: 0.9723 - recall: 0.9723\n",
      "Epoch 17/25\n",
      "7168/7168 [==============================] - 8s 1ms/step - loss: 0.1007 - precision: 0.9686 - recall: 0.9686\n",
      "Epoch 18/25\n",
      "7168/7168 [==============================] - 7s 1ms/step - loss: 0.0930 - precision: 0.9715 - recall: 0.9715\n",
      "Epoch 19/25\n",
      "7168/7168 [==============================] - 7s 1ms/step - loss: 0.0886 - precision: 0.9718 - recall: 0.9718\n",
      "Epoch 20/25\n",
      "7168/7168 [==============================] - 7s 1ms/step - loss: 0.1004 - precision: 0.9721 - recall: 0.9721\n",
      "Epoch 21/25\n",
      "7168/7168 [==============================] - 8s 1ms/step - loss: 0.1029 - precision: 0.9682 - recall: 0.9682\n",
      "Epoch 22/25\n",
      "7168/7168 [==============================] - 8s 1ms/step - loss: 0.0896 - precision: 0.9753 - recall: 0.9753\n",
      "Epoch 23/25\n",
      "7168/7168 [==============================] - 8s 1ms/step - loss: 0.0821 - precision: 0.9775 - recall: 0.9775\n",
      "Epoch 24/25\n",
      "7168/7168 [==============================] - 8s 1ms/step - loss: 0.0877 - precision: 0.9728 - recall: 0.9728\n",
      "Epoch 25/25\n",
      "7168/7168 [==============================] - 8s 1ms/step - loss: 0.0946 - precision: 0.9714 - recall: 0.9714\n",
      "Evaluation metrics: \n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.0883 - precision: 0.9787 - recall: 0.9787\n",
      "[0.08833855390548706, 0.9786551594734192, 0.9786551594734192]\n",
      "224/224 [==============================] - 0s 598us/step\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      All2()     0.9917    0.9329    0.9614      2043\n",
      "       Other     0.9739    0.9969    0.9852      5125\n",
      "\n",
      "   micro avg     0.9787    0.9787    0.9787      7168\n",
      "   macro avg     0.9828    0.9649    0.9733      7168\n",
      "weighted avg     0.9790    0.9787    0.9785      7168\n",
      " samples avg     0.9787    0.9787    0.9787      7168\n",
      "\n",
      "Confusion matrix: \n",
      "        All2()  Other\n",
      "All2()    1906    137\n",
      "Other       16   5109\n",
      "TEST\n",
      "Evaluation metrics: \n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.1125 - precision: 0.9375 - recall: 0.9375\n",
      "[0.11253499239683151, 0.9375, 0.9375]\n",
      "32/32 [==============================] - 0s 714us/step\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      All2()     1.0000    0.9375    0.9677      1024\n",
      "       Other     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.9375    0.9375    0.9375      1024\n",
      "   macro avg     0.5000    0.4688    0.4839      1024\n",
      "weighted avg     1.0000    0.9375    0.9677      1024\n",
      " samples avg     0.9375    0.9375    0.9375      1024\n",
      "\n",
      "Confusion matrix: \n",
      "        All2()  Other\n",
      "All2()     960     64\n",
      "Other        0      0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/doron/git/research/RESEARCH/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 836us/step\n",
      "Quantifier counts:  [  6. 994.]\n",
      "Support:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.MyClassifier at 0x7fdbed0e2910>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.learn(epochs=25, scene_num=1024, batch_size=1, verbose=1,\n",
    "                contrastive_quantifiers=natural_quantifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 500, 2)\n",
      "[array([[[1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]]], dtype=float32)]\n",
      "(None, 2)\n",
      "[array([[-0.29531276, -0.29531276],\n",
      "       [ 4.9191737 ,  4.9191737 ]], dtype=float32), array([0.8606959, 0.8606959], dtype=float32)]\n",
      "(None, 2)\n",
      "[array([[-12.725833 ,  12.7258415],\n",
      "       [-12.725833 ,  12.7258415]], dtype=float32), array([ 1.2970827, -1.2970849], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "conv = classifier._model.get_layer(name=\"conv\")\n",
    "print(conv.output_shape)\n",
    "print(conv.get_weights())\n",
    "\n",
    "dense = classifier._model.get_layer(name=\"dense\")\n",
    "print(dense.output_shape)\n",
    "print(dense.get_weights())\n",
    "\n",
    "softmax = classifier._model.get_layer(name=\"softmax\")\n",
    "print(softmax.output_shape)\n",
    "print(softmax.get_weights())\n",
    "\n",
    "# for quantifier_name, weights in zip(classifier._quantifier_names, \n",
    "# # , bias \n",
    "#                                           conv.get_weights()[0].transpose(),\n",
    "# #                                           conv.get_weights()[1].transpose()\n",
    "#                                          ):\n",
    "#     print(quantifier_name, weights)  # , bias)\n",
    "\n",
    "# for i in range(len(classifier._kernels)):\n",
    "#     dense_i = classifier._model.get_layer(name=\"dense_{i}\".format(i=i))\n",
    "#     print(dense_i.output_shape)\n",
    "#     print(dense_i.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "a = classifier.predict(classifier.prepare_scenes(All().generate_scenes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 1.]], dtype=float32), array([1000]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(a, axis=0, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
