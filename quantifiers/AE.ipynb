{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AE approach\n",
    "---\n",
    "The AE approach tries to let an AE look at scenes where a given quantifier q was used by a teacher (language speaker), this is repeated many times till whatever structure typical to scenes True under the q quantifier are encoded in the AE structure and each representation of this structure is given in the hidden vector. When learning is done and given a scene we use the AE as an anomaly classifier to decide whether the scene is True under the q quantifier. The idea is that after seeing many q True scenes a non q True scene will have relatively high reconstruction errors.\n",
    "\n",
    "Many types of AEs can be used and are implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### my class imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AE' from 'Q.models' (/home/doron/git/research/notebooks/quantifiers/Q/models.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-da99a92c6332>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'AE' from 'Q.models' (/home/doron/git/research/notebooks/quantifiers/Q/models.py)"
     ]
    }
   ],
   "source": [
    "from Q.quants import *\n",
    "from Q.models import AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# keras imports\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import SimpleRNN, LSTM, Dense, Conv1D, MaxPooling1D, UpSampling1D, Input, Bidirectional, RepeatVector, TimeDistributed, Dropout, LeakyReLU, Flatten\n",
    "from keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogicalDevice(name='/device:CPU:0', device_type='CPU'),\n",
       " LogicalDevice(name='/device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " LogicalDevice(name='/device:XLA_GPU:0', device_type='XLA_GPU'),\n",
       " LogicalDevice(name='/device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from keras import backend as K\n",
    "# K.tensorflow_backend._get_available_gpus()\n",
    "tf.config.list_logical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import partial, update_wrapper\n",
    "\n",
    "# def wrapped_partial(func, *args, **kwargs):\n",
    "#         partial_func = partial(func, *args, **kwargs)\n",
    "#         update_wrapper(partial_func, func)\n",
    "#         return partial_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AE Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DenseAE():\n",
    "    model = Sequential()\n",
    "    #encoding\n",
    "    model.add(Dense(75, activation='sigmoid', input_shape=(100, 3)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation='sigmoid'))\n",
    "    model.add(Dense(25, activation='sigmoid'))\n",
    "    #decoding\n",
    "    model.add(Dense(50, activation='sigmoid'))\n",
    "    model.add(Dense(75, activation='sigmoid'))\n",
    "    model.add(Dense(Quantifier.scenes_len, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def CNNAE():\n",
    "    model= Sequential()\n",
    "    #encoding\n",
    "    model.add(Conv1D(60,32, strides=1, activation='relu',padding='causal',input_shape=(Quantifier.scenes_len,1)))\n",
    "    model.add(Conv1D(80,10, strides=1, activation='relu',padding='causal'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv1D(100,5, strides=1, activation='relu',padding='causal'))\n",
    "    model.add(MaxPooling1D(1))\n",
    "    #decoding\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(300,activation='relu'))\n",
    "    model.add(Dense(1,activation='relu'))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def RNNAE():\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(SimpleRNN(15, activation='sigmoid', input_shape=(Quantifier.scenes_len, 1))))\n",
    "    model.add(Dropout(0.5))\n",
    "#     model.add(Bidirectional(SimpleRNN(15, activation='sigmoid', return_sequences=True)))\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(RepeatVector(Quantifier.scenes_len))\n",
    "    model.add(SimpleRNN(15, activation='sigmoid', return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "#     model.add(Bidirectional(SimpleRNN(25, activation='sigmoid', return_sequences=True)))\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def LSTMAE():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(15, activation='sigmoid', input_shape=(Quantifier.scenes_len, 1)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(RepeatVector(Quantifier.scenes_len))\n",
    "    model.add(LSTM(15, activation='sigmoid', return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def BLSTMAE():\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(15, activation='sigmoid', input_shape=(Quantifier.scenes_len, 1))))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(RepeatVector(Quantifier.scenes_len))\n",
    "    model.add(Bidirectional(LSTM(15, activation='sigmoid', return_sequences=True)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "batch_size = 10\n",
    "\n",
    "def learn(scenes):\n",
    "#     model = DenseAE()\n",
    "#     model = CNNAE()\n",
    "#     model = RNNAE()\n",
    "#     model = LSTMAE()\n",
    "    model = BLSTMAE()\n",
    "    plot_model(model, to_file='AE_model.png', show_shapes=True)\n",
    "#     model.fit(Quantifier.one_hot(scenes), scenes, batch_size=batch_size, epochs=num_epochs, verbose=1)\n",
    "    model.fit(scenes, scenes, batch_size=batch_size, epochs=num_epochs, verbose=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_quantifer(model, quantifier):\n",
    "    test_size = 10\n",
    "\n",
    "    test_scenes = generate_random_scenes(scenes_num=test_size)\n",
    "    test_labels = [quantifier.quantify(test_scene) for test_scene in test_scenes]\n",
    "    test_results = [model.evaluate(test_scene.reshape(1, -1, 1), \n",
    "                                   test_scene.reshape(1, -1, 1), verbose=0) for test_scene in test_scenes]\n",
    "    thresh = np.mean(test_results)\n",
    "    test_thresh = [test_result < thresh for test_result in test_results]\n",
    "    print(np.sum(np.array(test_labels) == np.array(test_thresh)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantifiers = [Between_3_6, Between_2_10, One, Two, Three, Ten, Some, Few, No, Every, Most]\n",
    "\n",
    "def test_quantifers(model):\n",
    "    test_size = 1000\n",
    "    test_results = pd.DataFrame(columns=[quantifier.__name__ for quantifier in quantifiers])\n",
    "\n",
    "#     for i in range(test_size):\n",
    "    test_result = []\n",
    "    for quantifier in quantifiers:\n",
    "        test_scenes = generate_quantified_scenes(quantifier, scenes_num=test_size)\n",
    "        test_result.append(model.evaluate(test_scenes, test_scenes, verbose=0))\n",
    "\n",
    "    test_results.loc[0] = test_result\n",
    "    return test_results    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.8308\n"
     ]
    }
   ],
   "source": [
    "# with tf.device(\"/cpu:0\"):\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    # fit model\n",
    "    model = learn(generate_quantified_scenes(Every))\n",
    "#     model = learn(generate_quantified_scenes(Every))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    test_quantifer(model, Every)\n",
    "#     models = [learn(generate_quantified_scenes(quantifier)) for quantifier in quantifiers]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
