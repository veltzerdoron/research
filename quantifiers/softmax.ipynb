{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax classifier approach\n",
    "---\n",
    "This approach assumes that quantifiers are learned as a group and that essentially each q quantifier example is a negative example for all other quantifiers q'.\n",
    "\n",
    "The classifier is in effect a solver for which q makes the sentence \"Q as are bs\" most likely given an input scene s.\n",
    "\n",
    "This enables us to use not onlt the quantifier quantify evaluation methods but the classifier in order to generate a teacher-student scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### my class imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from quants import *\n",
    "from models import Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras and TF imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, LSTM, Embedding, Dense, Conv1D, Input, Bidirectional, RepeatVector, Dropout, LeakyReLU, Flatten\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras backend:  tensorflow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[LogicalDevice(name='/device:CPU:0', device_type='CPU'),\n",
       " LogicalDevice(name='/device:XLA_CPU:0', device_type='XLA_CPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.1)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "print(\"Keras backend: \", tf.python.keras.backend.backend())\n",
    "tf.python.keras.backend.set_session(sess)\n",
    "tf.config.list_logical_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import partial, update_wrapper\n",
    "\n",
    "# def wrapped_partial(func, *args, **kwargs):\n",
    "#     |   partial_func = partial(func, *args, **kwargs)\n",
    "#         update_wrapper(partial_func, func)\n",
    "#         return partial_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep dense classifier model builder method\n",
    "def DDNNBuilder(quantifiers):\n",
    "    model= Sequential()\n",
    "    model.add(Dense(scene_len, activation=\"relu\", name=\"input\"))\n",
    "    model.add(Dropout(0.25, name=\"dropout_1\"))\n",
    "    model.add(Dense(100, activation=\"relu\", name=\"dense_2\"))\n",
    "    model.add(Dropout(0.25, name=\"dropout_2\"))\n",
    "    model.add(Dense(50, activation=\"relu\", name=\"dense_3\"))\n",
    "    model.add(Dropout(0.25, name=\"dropout_3\"))\n",
    "    model.add(Dense(len(quantifiers), activation='softmax', name=\"softmax_1\"))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Precision(),\n",
    "                                                                              tf.keras.metrics.Recall()])\n",
    "    return model, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense classifier model builder method\n",
    "def DNNBuilder(quantifiers):\n",
    "    model= Sequential()\n",
    "    model.add(Dense(scene_len, activation=\"relu\", name=\"input\"))\n",
    "    model.add(Dropout(0.5, name=\"dropout_1\"))\n",
    "    model.add(Dense(len(quantifiers), activation='softmax', name=\"softmax_1\"))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Precision(),\n",
    "                                                                              tf.keras.metrics.Recall()])\n",
    "    return model, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import initializers\n",
    "\n",
    "# Convolutional classifier model builder method\n",
    "def CNNBuilder(quantifiers):\n",
    "    model= Sequential()\n",
    "    model.add(Conv1D(filters=2, kernel_size=1, \n",
    "                     use_bias=False, \n",
    "                     input_shape=(scene_len, len(symbols)), name=\"conv_1\"))\n",
    "    model.add(Dropout(0.5, name=\"dropout_1\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(len(quantifiers),\n",
    "#                     kernel_initializer=\"constant\", trainable=False, use_bias=False, \n",
    "                    activation='softmax', name=\"softmax_1\"))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Precision(),\n",
    "                                                                              tf.keras.metrics.Recall()])\n",
    "    return model, True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifier sets for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_quantifiers = [The(), Both(), No(), All(), Some(), Most()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnatural_quantifiers = [MinMax(2, 10), MinMax(3, 6), Or([MinMax(2, 5), MinMax(10, 20)])]\n",
    "# unnatural_quantifiers = [MinMax(2, 5), MinMax(8, 10), MinMax(12, 15), MinMax(17, 20), MinMax(24, 30), MinMax(37, 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teach(classifier, min_len=0, max_len=scene_len, repeat=1, epochs=50, batch_size=10):\n",
    "    \"\"\"\n",
    "    This method teaches a classifier to classify its quantifiers\n",
    "    \n",
    "    repeat: teacher student learning for repeat # of rounds\n",
    "    epochs, batch_size: parameters passed to tensorflow learning\n",
    "    min_len, max_len: genereated scene length limits for training (to test generalization)\n",
    "    \"\"\"\n",
    "    last_classifier = None\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "#     with tf.device(\"/gpu:0\"):\n",
    "        # iterate while using the previous model as label generator\n",
    "        for _ in range(repeat):\n",
    "            # generate fit and test model\n",
    "            if last_classifier:\n",
    "                train_scenes_labels = classifier.generate_labeled_scenes(last_classifier, min_len, max_len)\n",
    "                test_scenes_labels = classifier.generate_labeled_scenes(last_classifier)\n",
    "            else:\n",
    "                train_scenes_labels = classifier.generate_labeled_scenes(min_len, max_len)\n",
    "                test_scenes_labels = classifier.generate_labeled_scenes()\n",
    "            classifier.fit(*train_scenes_labels, epochs=epochs, batch_size=batch_size)\n",
    "            classifier.test(*test_scenes_labels)\n",
    "            classifier.test_random(1000)\n",
    "            last_classifier = classifier.clone()\n",
    "        return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNBuilder model classifies ['All()' 'Both()' 'Most()' 'No()' 'Some()' 'The()']\n",
      "Epoch 1/50\n",
      "600/600 [==============================] - 0s 198us/step - loss: 1.8198 - precision_8: 0.2298 - recall_8: 0.1184\n",
      "Epoch 2/50\n",
      "600/600 [==============================] - 0s 88us/step - loss: 1.4717 - precision_8: 0.3465 - recall_8: 0.1966\n",
      "Epoch 3/50\n",
      "600/600 [==============================] - 0s 82us/step - loss: 1.4111 - precision_8: 0.3849 - recall_8: 0.2180\n",
      "Epoch 4/50\n",
      "600/600 [==============================] - 0s 82us/step - loss: 1.2406 - precision_8: 0.4116 - recall_8: 0.2344\n",
      "Epoch 5/50\n",
      "600/600 [==============================] - 0s 81us/step - loss: 1.2684 - precision_8: 0.4383 - recall_8: 0.2530\n",
      "Epoch 6/50\n",
      "600/600 [==============================] - 0s 82us/step - loss: 1.1360 - precision_8: 0.4506 - recall_8: 0.2629\n",
      "Epoch 7/50\n",
      "600/600 [==============================] - 0s 81us/step - loss: 1.0467 - precision_8: 0.4801 - recall_8: 0.2868\n",
      "Epoch 8/50\n",
      "600/600 [==============================] - 0s 82us/step - loss: 1.0653 - precision_8: 0.5001 - recall_8: 0.3041\n",
      "Epoch 9/50\n",
      "600/600 [==============================] - 0s 81us/step - loss: 0.9470 - precision_8: 0.5158 - recall_8: 0.3196\n",
      "Epoch 10/50\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.9322 - precision_8: 0.5320 - recall_8: 0.3368\n",
      "Epoch 11/50\n",
      "600/600 [==============================] - ETA: 0s - loss: 0.5608 - precision_8: 0.5394 - recall_8: 0.34 - 0s 82us/step - loss: 0.8866 - precision_8: 0.5462 - recall_8: 0.3522\n",
      "Epoch 12/50\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.8560 - precision_8: 0.5606 - recall_8: 0.3674\n",
      "Epoch 13/50\n",
      "600/600 [==============================] - 0s 84us/step - loss: 0.7687 - precision_8: 0.5732 - recall_8: 0.3812\n",
      "Epoch 14/50\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.7530 - precision_8: 0.5860 - recall_8: 0.3955\n",
      "Epoch 15/50\n",
      "600/600 [==============================] - 0s 84us/step - loss: 0.7089 - precision_8: 0.5967 - recall_8: 0.4079\n",
      "Epoch 16/50\n",
      "600/600 [==============================] - 0s 84us/step - loss: 0.6794 - precision_8: 0.6069 - recall_8: 0.4195\n",
      "Epoch 17/50\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.7112 - precision_8: 0.6156 - recall_8: 0.4312\n",
      "Epoch 18/50\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.6849 - precision_8: 0.6229 - recall_8: 0.4411\n",
      "Epoch 19/50\n",
      "600/600 [==============================] - 0s 84us/step - loss: 0.6496 - precision_8: 0.6313 - recall_8: 0.4516\n",
      "Epoch 20/50\n",
      "600/600 [==============================] - 0s 90us/step - loss: 0.6202 - precision_8: 0.6397 - recall_8: 0.4621\n",
      "Epoch 21/50\n",
      "600/600 [==============================] - 0s 84us/step - loss: 0.6210 - precision_8: 0.6465 - recall_8: 0.4709\n",
      "Epoch 22/50\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.5945 - precision_8: 0.6533 - recall_8: 0.4801\n",
      "Epoch 23/50\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.6036 - precision_8: 0.6598 - recall_8: 0.4882\n",
      "Epoch 24/50\n",
      "600/600 [==============================] - 0s 84us/step - loss: 0.5753 - precision_8: 0.6663 - recall_8: 0.4961\n",
      "Epoch 25/50\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5762 - precision_8: 0.6721 - recall_8: 0.5039\n",
      "Epoch 26/50\n",
      "600/600 [==============================] - 0s 84us/step - loss: 0.5981 - precision_8: 0.6764 - recall_8: 0.5107\n",
      "Epoch 27/50\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.5531 - precision_8: 0.6801 - recall_8: 0.5164\n",
      "Epoch 28/50\n",
      "600/600 [==============================] - 0s 86us/step - loss: 0.5439 - precision_8: 0.6843 - recall_8: 0.5222\n",
      "Epoch 29/50\n",
      "600/600 [==============================] - 0s 84us/step - loss: 0.5524 - precision_8: 0.6886 - recall_8: 0.5286\n",
      "Epoch 30/50\n",
      "600/600 [==============================] - 0s 86us/step - loss: 0.5575 - precision_8: 0.6922 - recall_8: 0.5344\n",
      "Epoch 31/50\n",
      "600/600 [==============================] - 0s 84us/step - loss: 0.5474 - precision_8: 0.6950 - recall_8: 0.5388\n",
      "Epoch 32/50\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.5054 - precision_8: 0.6983 - recall_8: 0.5440\n",
      "Epoch 33/50\n",
      "600/600 [==============================] - 0s 86us/step - loss: 0.4986 - precision_8: 0.7021 - recall_8: 0.5492\n",
      "Epoch 34/50\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.4682 - precision_8: 0.7060 - recall_8: 0.5547\n",
      "Epoch 35/50\n",
      "600/600 [==============================] - 0s 88us/step - loss: 0.5318 - precision_8: 0.7094 - recall_8: 0.5598\n",
      "Epoch 36/50\n",
      "600/600 [==============================] - 0s 86us/step - loss: 0.4884 - precision_8: 0.7125 - recall_8: 0.5643\n",
      "Epoch 37/50\n",
      "600/600 [==============================] - 0s 86us/step - loss: 0.5115 - precision_8: 0.7154 - recall_8: 0.5688\n",
      "Epoch 38/50\n",
      "600/600 [==============================] - 0s 86us/step - loss: 0.5157 - precision_8: 0.7180 - recall_8: 0.5729\n",
      "Epoch 39/50\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.5070 - precision_8: 0.7203 - recall_8: 0.5769\n",
      "Epoch 40/50\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.4611 - precision_8: 0.7234 - recall_8: 0.5814\n",
      "Epoch 41/50\n",
      "600/600 [==============================] - 0s 86us/step - loss: 0.4758 - precision_8: 0.7262 - recall_8: 0.5854\n",
      "Epoch 42/50\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.4529 - precision_8: 0.7291 - recall_8: 0.5896\n",
      "Epoch 43/50\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.4464 - precision_8: 0.7324 - recall_8: 0.5939\n",
      "Epoch 44/50\n",
      "600/600 [==============================] - 0s 84us/step - loss: 0.4509 - precision_8: 0.7353 - recall_8: 0.5980\n",
      "Epoch 45/50\n",
      "600/600 [==============================] - 0s 84us/step - loss: 0.4362 - precision_8: 0.7376 - recall_8: 0.6016\n",
      "Epoch 46/50\n",
      "600/600 [==============================] - 0s 84us/step - loss: 0.4669 - precision_8: 0.7401 - recall_8: 0.6052\n",
      "Epoch 47/50\n",
      "600/600 [==============================] - 0s 84us/step - loss: 0.4555 - precision_8: 0.7421 - recall_8: 0.6085\n",
      "Epoch 48/50\n",
      "600/600 [==============================] - 0s 84us/step - loss: 0.4465 - precision_8: 0.7440 - recall_8: 0.6118\n",
      "Epoch 49/50\n",
      "600/600 [==============================] - 0s 86us/step - loss: 0.4320 - precision_8: 0.7461 - recall_8: 0.6153\n",
      "Epoch 50/50\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.4040 - precision_8: 0.7486 - recall_8: 0.6190\n",
      "Evaluation metrics: \n",
      "6000/6000 [==============================] - 0s 19us/step\n",
      "[1.1788522141774496, 0.7336052656173706, 0.6105473041534424]\n",
      "Confusion matrix: \n",
      "[[808  53  76   0  27  36]\n",
      " [  0 188   0   0   0 812]\n",
      " [312  56 175   4 378  75]\n",
      " [  0  58   0 813   1 128]\n",
      " [298   5  83 146 459   9]\n",
      " [  0 150   0   0   0 850]]\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       All()     0.5698    0.8080    0.6683      1000\n",
      "      Both()     0.3686    0.1880    0.2490      1000\n",
      "      Most()     0.5240    0.1750    0.2624      1000\n",
      "        No()     0.8442    0.8130    0.8283      1000\n",
      "      Some()     0.5306    0.4590    0.4922      1000\n",
      "       The()     0.4450    0.8500    0.5842      1000\n",
      "\n",
      "    accuracy                         0.5488      6000\n",
      "   macro avg     0.5470    0.5488    0.5141      6000\n",
      "weighted avg     0.5470    0.5488    0.5141      6000\n",
      "\n",
      "Quantifier counts:  [ 41   0 291   4 664]\n",
      "Support:  1000\n",
      "Accuracy:  0.664\n"
     ]
    }
   ],
   "source": [
    "natural_classifier = teach(Classifier(natural_quantifiers, CNNBuilder), epochs=50, max_len=100)\n",
    "# natural_classifier = teach(Classifier(natural_quantifiers, DNNBuilder), epochs=500, repeat=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNNBuilder model classifies ['MinMax(m=2,M=10)' 'MinMax(m=3,M=6)'\n",
      " 'Or(MinMax(m=2,M=5),MinMax(m=10,M=20))']\n",
      "Epoch 1/50\n",
      "300/300 [==============================] - 0s 478us/step - loss: 3.0564 - precision_11: 0.3747 - recall_11: 0.3629\n",
      "Epoch 2/50\n",
      "300/300 [==============================] - 0s 260us/step - loss: 1.8069 - precision_11: 0.3828 - recall_11: 0.3511\n",
      "Epoch 3/50\n",
      "300/300 [==============================] - 0s 262us/step - loss: 1.3043 - precision_11: 0.3854 - recall_11: 0.3332\n",
      "Epoch 4/50\n",
      "300/300 [==============================] - 0s 268us/step - loss: 1.1271 - precision_11: 0.3816 - recall_11: 0.2793\n",
      "Epoch 5/50\n",
      "300/300 [==============================] - 0s 243us/step - loss: 1.0762 - precision_11: 0.3861 - recall_11: 0.2412\n",
      "Epoch 6/50\n",
      "300/300 [==============================] - 0s 239us/step - loss: 1.0821 - precision_11: 0.3935 - recall_11: 0.2168\n",
      "Epoch 7/50\n",
      "300/300 [==============================] - 0s 245us/step - loss: 1.0622 - precision_11: 0.3984 - recall_11: 0.2021\n",
      "Epoch 8/50\n",
      "300/300 [==============================] - 0s 247us/step - loss: 1.0854 - precision_11: 0.4032 - recall_11: 0.1913\n",
      "Epoch 9/50\n",
      "300/300 [==============================] - 0s 241us/step - loss: 1.0522 - precision_11: 0.4104 - recall_11: 0.1794\n",
      "Epoch 10/50\n",
      "300/300 [==============================] - 0s 251us/step - loss: 1.0889 - precision_11: 0.4151 - recall_11: 0.1722\n",
      "Epoch 11/50\n",
      "300/300 [==============================] - 0s 231us/step - loss: 1.0533 - precision_11: 0.4194 - recall_11: 0.1681\n",
      "Epoch 12/50\n",
      "300/300 [==============================] - 0s 249us/step - loss: 1.0396 - precision_11: 0.4285 - recall_11: 0.1651\n",
      "Epoch 13/50\n",
      "300/300 [==============================] - 0s 247us/step - loss: 1.0631 - precision_11: 0.4344 - recall_11: 0.1618\n",
      "Epoch 14/50\n",
      "300/300 [==============================] - 0s 248us/step - loss: 1.0365 - precision_11: 0.4401 - recall_11: 0.1590\n",
      "Epoch 15/50\n",
      "300/300 [==============================] - 0s 243us/step - loss: 1.0256 - precision_11: 0.4491 - recall_11: 0.1597\n",
      "Epoch 16/50\n",
      "300/300 [==============================] - 0s 255us/step - loss: 1.0083 - precision_11: 0.4561 - recall_11: 0.1605\n",
      "Epoch 17/50\n",
      "300/300 [==============================] - 0s 227us/step - loss: 1.0196 - precision_11: 0.4594 - recall_11: 0.1604\n",
      "Epoch 18/50\n",
      "300/300 [==============================] - 0s 241us/step - loss: 1.0134 - precision_11: 0.4661 - recall_11: 0.1617\n",
      "Epoch 19/50\n",
      "300/300 [==============================] - 0s 242us/step - loss: 0.9837 - precision_11: 0.4731 - recall_11: 0.1624\n",
      "Epoch 20/50\n",
      "300/300 [==============================] - 0s 251us/step - loss: 1.0133 - precision_11: 0.4833 - recall_11: 0.1659\n",
      "Epoch 21/50\n",
      "300/300 [==============================] - 0s 256us/step - loss: 1.0101 - precision_11: 0.4900 - recall_11: 0.1659\n",
      "Epoch 22/50\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.9986 - precision_11: 0.4952 - recall_11: 0.1669\n",
      "Epoch 23/50\n",
      "300/300 [==============================] - 0s 255us/step - loss: 1.0081 - precision_11: 0.5005 - recall_11: 0.1672\n",
      "Epoch 24/50\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.9622 - precision_11: 0.5047 - recall_11: 0.1682\n",
      "Epoch 25/50\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.9836 - precision_11: 0.5131 - recall_11: 0.1709\n",
      "Epoch 26/50\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.9621 - precision_11: 0.5197 - recall_11: 0.1719\n",
      "Epoch 27/50\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.9919 - precision_11: 0.5247 - recall_11: 0.1741\n",
      "Epoch 28/50\n",
      "300/300 [==============================] - 0s 252us/step - loss: 0.9860 - precision_11: 0.5306 - recall_11: 0.1749\n",
      "Epoch 29/50\n",
      "300/300 [==============================] - 0s 251us/step - loss: 0.9473 - precision_11: 0.5371 - recall_11: 0.1755\n",
      "Epoch 30/50\n",
      "300/300 [==============================] - 0s 240us/step - loss: 1.0167 - precision_11: 0.5435 - recall_11: 0.1775\n",
      "Epoch 31/50\n",
      "300/300 [==============================] - 0s 259us/step - loss: 0.9523 - precision_11: 0.5482 - recall_11: 0.1763\n",
      "Epoch 32/50\n",
      "300/300 [==============================] - 0s 235us/step - loss: 0.9483 - precision_11: 0.5527 - recall_11: 0.1781\n",
      "Epoch 33/50\n",
      "300/300 [==============================] - 0s 249us/step - loss: 0.9382 - precision_11: 0.5578 - recall_11: 0.1803\n",
      "Epoch 34/50\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.9178 - precision_11: 0.5635 - recall_11: 0.1834\n",
      "Epoch 35/50\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.9377 - precision_11: 0.5683 - recall_11: 0.1851\n",
      "Epoch 36/50\n",
      "300/300 [==============================] - 0s 229us/step - loss: 0.9433 - precision_11: 0.5732 - recall_11: 0.1877\n",
      "Epoch 37/50\n",
      "300/300 [==============================] - 0s 245us/step - loss: 0.9087 - precision_11: 0.5786 - recall_11: 0.1905\n",
      "Epoch 38/50\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.8524 - precision_11: 0.5830 - recall_11: 0.1936\n",
      "Epoch 39/50\n",
      "300/300 [==============================] - 0s 255us/step - loss: 0.8287 - precision_11: 0.5905 - recall_11: 0.1983\n",
      "Epoch 40/50\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.8157 - precision_11: 0.5986 - recall_11: 0.2040\n",
      "Epoch 41/50\n",
      "300/300 [==============================] - 0s 258us/step - loss: 0.8536 - precision_11: 0.6054 - recall_11: 0.2091\n",
      "Epoch 42/50\n",
      "300/300 [==============================] - 0s 238us/step - loss: 0.7901 - precision_11: 0.6126 - recall_11: 0.2144\n",
      "Epoch 43/50\n",
      "300/300 [==============================] - 0s 251us/step - loss: 0.8140 - precision_11: 0.6188 - recall_11: 0.2190\n",
      "Epoch 44/50\n",
      "300/300 [==============================] - 0s 221us/step - loss: 0.8001 - precision_11: 0.6257 - recall_11: 0.2246\n",
      "Epoch 45/50\n",
      "300/300 [==============================] - 0s 239us/step - loss: 0.8509 - precision_11: 0.6300 - recall_11: 0.2283\n",
      "Epoch 46/50\n",
      "300/300 [==============================] - 0s 245us/step - loss: 0.7695 - precision_11: 0.6361 - recall_11: 0.2328\n",
      "Epoch 47/50\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.8293 - precision_11: 0.6414 - recall_11: 0.2375\n",
      "Epoch 48/50\n",
      "300/300 [==============================] - 0s 251us/step - loss: 0.7960 - precision_11: 0.6448 - recall_11: 0.2412\n",
      "Epoch 49/50\n",
      "300/300 [==============================] - 0s 229us/step - loss: 0.8110 - precision_11: 0.6492 - recall_11: 0.2459\n",
      "Epoch 50/50\n",
      "300/300 [==============================] - 0s 249us/step - loss: 0.7586 - precision_11: 0.6529 - recall_11: 0.2497\n",
      "Evaluation metrics: \n",
      "3000/3000 [==============================] - 0s 30us/step\n",
      "[1.252001072883606, 0.6154882311820984, 0.24415980279445648]\n",
      "Confusion matrix: \n",
      "[[521  58 421]\n",
      " [531  44 425]\n",
      " [549  48 403]]\n",
      "Classification report: \n",
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "                     MinMax(m=2,M=10)     0.3254    0.5210    0.4006      1000\n",
      "                      MinMax(m=3,M=6)     0.2933    0.0440    0.0765      1000\n",
      "Or(MinMax(m=2,M=5),MinMax(m=10,M=20))     0.3227    0.4030    0.3584      1000\n",
      "\n",
      "                             accuracy                         0.3227      3000\n",
      "                            macro avg     0.3138    0.3227    0.2785      3000\n",
      "                         weighted avg     0.3138    0.3227    0.2785      3000\n",
      "\n",
      "Quantifier counts:  [414 166 420]\n",
      "NO SUPPORT\n"
     ]
    }
   ],
   "source": [
    "# unnatural_model = teach(Classifier(unnatural_quantifiers, CNNBuilder), epochs=50, max_len=100)\n",
    "unnatural_model = teach(Classifier(unnatural_quantifiers, DNNBuilder), epochs=50, max_len=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
